#+TITLE: Rust in 2 hours
#+AUTHOR: Aleksandr Petrosyan

* Preface
This is a high level overview document about the Rust programming language.  The reason this document exists is to provide people who have to learn Rust at some point a general overview, without the usual dogmatism.  This is good to nudge teams that were considering Rust to using it and to avert catastrophe for projects for which it is a poor fit.

I firmly believe that either a blind endorsement or misinformed dogmatic rejection of the language are both detrimental to society.  Despite my humble expertise in Rust, and a relatively good overview of programming languages, I believe that this document can be a valuable tool.  However, this is in no way an in-depth analysis, and I would recommend using this document as a start for one's own research using the provided resources.

* Overview
Rust is a multi-paradigm programming language that supports procedural, object-oriented and functional programming as well as relatively niche paradigms such as actor-based programming.  However, it does not fit into either of those niches completely.  In conjunction with relatively good performance, a vibrant community and a reliance on the =libc= as the only runtime component, Rust can fill the niches previously occupied by C++, while its choice to support a limited form of compile-time user-specified code transformation/generation (via procedural macros) allow it to compete with Python and Go for backend development.

Rust is a complex language.  Much of its complexity stemming from the rules imposed by the language designers, rather than the sheer number of features.  Procedural macros allow library developers to impose additional rules, which more often than not allows Rust to be explored by trial and error.  For someone well-versed in Haskell and C++, required reading to learn Rust can be reduced to none, as the process from installing =rustup= to running =cargo build= is self documenting.

Rust is a language that plants itself firmly in the camp of pragmatic long feedback cycle development.  A proficient Rust engineer is able to skirt around and anticipate compilation errors, which given strict typing, strong soundness requirements and many issues particularly pertaining to incomplete and/or unimplemented features, is a lot harder than one would aniticipate.

Rust programming is unlike programming in other systems programming languages, as it does not allow the programmer to defer confronting problems, and over-abstract to hide poor design decisions.  It is a language best suited for programming libraries, with a similarly robust toolkit for producing complete applications either using the CLI or graphical toolkits.

It is a language that is used in the vast majority of blockchain systems.  Among the features that make it a good choice are
1) Borrow checking, which elides the need for garbage collection and  providing similar memory safety.
2) A sane concurrent programming paradigm, making it easier to write both threaded and asynchronous multiprocessing applications.
3) Strong static analysis tools, preventing implicit programming errors, such as over/under flow, unhandled error conditions, type mismatch etc.
4) Robust coverage of LLVM targets.  It should be noted that due to the dependence on the platform-specific =libc=, the =zig= programming language has slightly better coverage.
5) Rust is the preferred language for working with WASM both client and server-side.
6) Strong FFI programming paradigm.  One does not have an implicit ABI, and one has thorough control over memory layout as well as potential pitfalls.
7) Rust allows the user to specify additional compile-time constraints with thorough guidance via procedural macros.


Rust is used for the implementation of some of the ledgers in the Ethereum protocol, and all of the Solana software stack.  It is used in Parity Substrate (Polkadot ecosystem), and with very few exceptions is the language of choice for writing one's own blockchain protocol.

Finally, Rust is the first language since C to be used for the Linux kernel.  It was directly endorsed by the white house in lieu of traditional programming in "memory unsafe" languages such as C, C++, FORTRAN, Pascal, Ada, and many more.

It is a flourishing ecosystem of libraries, packages and professionals.

* Procedural Rust



Rust has a pragmatic approach to procedural programming.  In most situations, one is encouraged to write the code in a procedural style, without over-abstraction.

** Hello world
To start things off, this is what a hello-world program would look like[fn:1].
#+BEGIN_SRC rust
  fn main() {
	  println!("Hello world");
  }
#+END_SRC
The =main= function is an OS entrypoint.  The Rust compiler abstracts the unix-specific aspects of the entrypoint: note the absence of arguments as input, the usage of the =println!= macro in lieu of the =libc= =printf= function, lack of return in either the signature of main, or implicit =return 0=.  For all intents and purposes, these abstractions are almost never a problem, and allow the programmer to live in a world of coherent abstractions.

** TODO Crates, compilation, cargo

** Variables

Like many similar languages, Rust supports a Von-Neumann model:  variables can be regarded as containers for values.

Each container has exactly one type.  The following primitive numerical types are supported:

| Type |
|------|
| u8   |
| u16  |
| u32  |
| u64  |
| u128 |
#+CAPTION: Unsigned integer types

| Type |
|------|
| i8   |
| i16  |
| i32  |
| i64  |
| i128 |
#+CAPTION: Signed integer types

Each container must be initialised to a value, before use, that is of the same type as the container.  Failure to do so is a compilation error, Rust can keenly track these situations, more on that later.  The following is a comprehensive example of possible variable declarations.
#+BEGIN_SRC rust
  let good_type: u64 = 0_u64;
  let good_deferred_init;

  let mut inferred_type = 0_usize;
  let bad_value: u64 = -1_i32;	// bad: unsigned box, signed value
  let bad_type: u64 = 0_usize;	// bad: usize is not the same as u64
  good_deferred_init = 3;			// ok: type i32
  let bad_init;					// bad: not initialised at all
#+END_SRC

All variables must be initialised once.  The programmer must opt into mutating the value afterwards.

Each variable is confined to a scope, that is delimited by curly brace pairs.  A =let= expression can be used to shadow a variable within a particular scope, with a type that might be different.

#+BEGIN_SRC rust
  start = 0_i32;
  // Illegal, need `let`
  let start = 0_u8;
  // legal init
  let start = 0_i8;
  // legal shadow
  {
	  let mut start = 0_u16;
	  // legal shadow
	  start += 1_u16;					// No ++ operator :(
	  // legal, this `start` is mutable.
  }
  start -= 1_i8;
  // Illegal.

  let start: u128;
  // All legal
  start = 0_u64;
  // illegal, because the type of `start` must be `u128`
#+END_SRC



** Expressions, Control flow

Rust is an expression-based language.  An expression is composed of literals, variables, function calls, and operators[fn:2].  Variables are evaluated eagerly.  There are two distinct types, ones which indicate a location, (called place expressions) and the rest are value expressions.

All expressions produce a value, some expressions have an effect on the surrounding code.  A literal is an expression that only produces a value.  An assignment, by contrast produces both a value, and an effect, and arguably the effect is more important. All values produced by expressions can be assigned to a variable.

A block: region delimited by curly braces, is also an expression:
#+BEGIN_SRC rust
  let block = {
	  let answer = 22;
	  let question = 20;
	  question;
	  answer + question
  };
  // block == 42
  #+END_SRC
Note the absence of the semicolon in the line containing the expression =answer+question=, but the presence of a semicolon after the initialisation.  If the semicolon were added, this would still be valid Rust, but the value (and type) of block would be =()= known as =unit=.  This special type is what most expressions in Rust evaluate to, even though you as a programmer are unlikely to write it explicitly.

Rust supports many of the usual ALGOL-heritage control constructs.  This includes =if/else=, =while=, =for=.  In Rust, these constructs are also expressions, meaning that they produce a value.

The boolean conditional =if= works by evaluating the expression that follows the keyword, and then evaluating the contents of the following curly braces.  For example:

  #+BEGIN_SRC rust
	let value_of_if = if true { false; }
	// value_of_if == ()
#+END_SRC
An =if= is allowed to evaluate to the trivial type =()=.  Any other value with only one =if= would lead to inconsistency in the type of the =value_of_if= variable.

If the =if= has an =else= block, however, the value is allowed to be of any other type, provided both the types of the =if= and =else= are the same:
#+BEGIN_SRC rust
let answer: i32 = if question_about_meaning_of_life { 42 } else { -1 }
#+END_SRC

For obvious reasons, the =while= loop operates much like the lone =if= expression, evaluating to =()=.

The =for= loop operates more similarly to Python or PASCAL, in that it provides a bound value that is taken from a particular collection.  The precise mechanism for this we shall cover in a later chapter.  Similarly to =while= and despite there being a natural[fn:3] value to which the =for= expression could evaluate, it too evaluates to =()=.

These loops interact in the usual way with the =break= and =continue= keywords.  They typically either exit or skip the execution of statements in the first enclosing loop.  If there is more than one loop, the programmers disambiguate by assigning labels.

#+BEGIN_SRC rust
  'outer: for i in 1..=5 {
	  for j in 1..=200 {
		  if j > 4 {
			  break;
			  // equivalent to `continue 'outer;`
		  }
		  if i >= 2 {
			  break 'outer;
		  }
	  }
  }
#+END_SRC
One keyword that differentiates Rust from other programming languages is the =loop= keyword.  It is an endless loop, that must be exited with the =break= keyword, or not at all (/e.g./ in event loops, REPL /etc./).  This is also the reason for differentiating loop labels with single quote marks (/e.g./ ='outer= instead of =outer=); because =loop= expressions are allowed to evaluate to non-trivial values.  In this case =break= can be used as a regular =return= statement in a function[fn:4].

#+BEGIN_SRC rust
let (mut a, mut b) = (1, 1);
let result = loop {
	if b > 10 {
		break b;
	}
	let c = a + b;
	a = b;
	b = c;
};
#+END_SRC


#+BEGIN_ASIDE
This convention might seem problematic at first; indeed this was one of the main criticisms of Pascal.  However, this convention allows shorter code, that is also more explicit about the dependency chains.

It is a common situation where a lot of values must be constructed, so that then a few other dependent values are initialised.  This code if written out linearly is difficult to read, as it is a dry sequence of definitions and assignments.  However, if the base values are only needed to construct the dependent values, one can group those into anonymous blocks.

This can be extended to situations wherein state is being modified as well.  Imposing a scope and shadowing temporarily mutable values, allows one to know which values are yet to be mutated, and which are immutable.

This approach is reminiscent of [[http://number-none.com/blow/blog/programming/2014/09/26/carmack-on-inlined-code.html][style C of John Carmack]], but with crucial improvements.  Namely, the local variables are localised, the variables whose state is used more than once are naturally declared at the outer scope, giving one a structural insight into the code organisation.  The comments are optional, and the function of a code fragment can be gleaned from the value that is being constructed.  As such, it provides the sequential narrative of inline declarations, as well as the readability improvements associated to grouping logically connected operations.
#+END_ASIDE

** Arrays, borrows, slices

Rust supports contiguous homogeneously typed collections at the language level.  The following is an example of an array of bytes, that is the ASCII string for "hello world".
#+BEGIN_SRC rust
let array: [u8; _] = b"hello world";
#+END_SRC
In this example, we could have omitted the type signature, as it would be inferred.  We chose to specify the type of each element: =u8=, but not to specify the number of elements.  We have also chosen to use the array literal syntax for ASCII strings.  Including any UTF-8 non-ASCII characters would result in a compilation error.

Like in PASCAL, arrays of different lengths are considered different types.
#+BEGIN_SRC rust
  let array: [u8; 3] = b"hello world"; // Type error; length
  let array: [char; 3] = ['a', 'b', 'c']; // OK
  let array: [char; 4] = "abcd";			// OK
  let array: [u8; 4] = "abcd";			// Type error; char is not u8
  let array: [char, 4] = b"abcd";			// Type error; u8 is not the same type as char
#+END_SRC
It should also be noted, that =char= is a distinct type from =u8=, and that Rust strings (more on them later), are not arrays of either =char= or =u8=.  Consequently, the problems that plagued PASCAL do not affect Rust, for reasons that shall become clear shortly.

Rust does not support C/C++ style references and pointers.  For historical reasons Rust follows the convention of those languages for its closest analogues to those concepts, however, the semantics attached to those analogues are very different.

While variables typically have a memory address, unlike most procedural languages, Rust enforces that these memory addresses be taken only while the variables are in scope.  So for example the following code shall fail to compile:

#+BEGIN_SRC rust
  let reference: &i32;

  {
	  let temp = 0;
	  reference = &temp;
  }

  *reference = 42
  // UB: temp must be `free`d by now.
#+END_SRC

All addresses in Rust can be safely considered to be valid, unless a subsystem of the Rust compiler, known as the borrow checker, states that a variable, in this case =temp= doesn't live long-enough[fn:5].

For reasons that shall become apparent later, Rust refers to these addresses as borrows, to delineate that unlike in C, where taking a reference is a simple operation, in Rust, the same operation has more implications.  The inverse operation to a =borrow= is a =dereference= and it largely follows the same conventions as C.

Unlike C, a variable in Rust is only mutable if explicitly marked as mutable.  An even stricter requirement is imposed on references that are allowed to mutate the borrowed value, known as mutable borrows.  To mutate elements of an array, both the array itself as well as the borrow of said array must be marked explicitly as mutable.  For example:
#+BEGIN_SRC rust
  let mut vec: [u8; 3] = [1, 2, 3];

  for i in &mut vec {
	  *i += 50;
  }

  // vec = [51, 52, 53]
#+END_SRC

The borrow checker statically verifies that there is no converting an immutable reference to a mutable one, similar to casting away =const= in C.  Any attempt to take another mutable or immutable[fn:7] reference to the same array =vec= (for example inside the =for= loop)  would also be a compilation error, as only one mutable borrow is allowed at a time.

#+BEGIN_ASIDE
The borrow checker algorithm is not perfect; whenever it sees code that *could* be borrowing the same variable's address mutably twice, it will reject that code.

For situations where that would lead to great inefficiencies, users are to use =unsafe=, however, it is highly recommended to avoid =unsafe=, unless one has exhausted all other possibilities.
#+END_ASIDE

One final point to cover is references to arrays.  In Rust arrays of two different sizes have two different types.  This necessitates introducing two ways of borrowing an array: =&[u8; 3]= which is a single machine word "pointer" to the beginning of the array (with the size known at compile time), and =&[u8]=, a fat pointer containing the length as part of the runtime parameters, which is known as a slice.

Both use the same syntax, but given that compile time information provides room for optimisations, the programmer is given no control over which borrow occurs for any given scenario.

** Operators

Rust operators are strictly typed.  This means that in =a+b=, both =a= and =b= must be of the same type.  Some types, for which other languages provide an automatic coercion, /e.g./ =u8= to =u16=, must be explicitly cast to the appropriate type:
#+BEGIN_SRC rust
  let a = 1u8;
  let b = 2u16;
  let c = a + (b as u8);			// Truncation warning
  let d = (a as u16) + b;
  let err = a + b;				// Type Error
#+END_SRC

Rust permits truncating conversions, but the static analysis tool =clippy= is able to quickly find and warn about these problems.

Rust operators are overloaded and user-overload-able, via the =trait= mechanism which we shall cover in the object-oriented part of this book.  For the time being, suffice it to say that the plus operator that acts on =u16= is not the same as =+= acting on =u8=.  This shall become important when dealing with strings.

** Functions

Rust calls procedures[fn:8] functions, without differentiating side-effect-free functions from procedures.

Function signatures as well as argument type declarations are right-associative.

#+BEGIN_SRC rust
  fn function(arg1: u32, arg2: i32, arg3: u128) -> u128 {
	  arg3
  }
#+END_SRC
Functions  evaluate to the value of the block that constitutes its body.  In this example the function body could be rewritten to =return arg3;= without changing anything.

No type outside the function body is inferred, so the function must always specify the type of each argument.

All data that the function is allowed to read comprises its arguments and special global values defined using the =const= keyword.  For the time being it can be assumed that this implies that no global shared state is permitted, but as we shall see later, this is not the case.

The functions must rigidly adhere to the type signature.  No implicit conversions in standard functions is permitted to occur, so arguments must be explicitly cast at the call site.

Functions that do not participate in C-ABI linkage are not variadic.

** Introduction to Macros

Macros are one of the key differentiating factors of Rust from other systems programming languages.  Macros are typically used to generate valid Rust code that no reasonable human being would be able to interpret or write, in addition to imposing other restrictions.

Macros do not have access to the type system, but thanks to strict typing, macros can typically do rudimentary type checking by hijacking the type checking in the generated code.

As such, there are multiple types of macros, of which we shall only cover one type: function-like macros.

Unlike functions, which have a fixed number of arguments, and are strictly type checked, a function-like macro can accept any form of input.  Technically all macros accept one argument, but that argument can be a delimited collection of expressions, which act as if they were a variadic function or macro.

We have already seen one example, the =println!= macro.  All function like macros are postfixed by an exclamation mark to differentiate them from functions.

** The formatting mini-language

The =println= macro is worth going into.  The first "argument" of =println!= is a format "string".  Unlike =printf= in C, this argument string is not an actual string[fn:11], and must be specified in-line as a string literal.  This format string is parsed at compilation time, and if there are no format markers, the string is printed as is.

The format markers constitute a mini-language.  Most primitive types can be printed directly, via an empty pair of curly braces:
#+BEGIN_SRC rust
  let answer = 42;
  println!("Hello world! The answer is {}", answer);
#+END_SRC
The empty pair is called a positional format marker, and for each positional format marker, there must be a comma delimited in-line list of variables that must be printed, in the order specified by positional format markers.

Named format markers allow one to assign a name in the format string, and in the variable list, assign variables to the named markers.  If the name of the format marker corresponds to an in-scope variable, the assignment can be omitted.

#+BEGIN_SRC rust
  let world_ordinal = 3;
  println!("Hello World number {world}! The answer is {answer}", world=world_ordinal)
#+END_SRC

#+BEGIN_ASIDE
My personal recommendation is to consider using /named/ format markers almost always; definitely in cases where there's more than one format marker.

Additionally, I should advise against mixing positional and named markers.
#+END_ASIDE

One has access to a rich set of formatting options, including
- fill,
- alignment,
- width
- formatting of numerical literals in many bases, including binary, hexadecimal, octal.
- Precision control for floating point numbers
- Localisation (for locales where the decimal separator is different) etc.

#+BEGIN_ASIDE
The =println!= and =eprintln!= macros (printing to =stderr=) are included in the so-called prelude.  This is a collection of commonly used constructs that are imported by default.
#+END_ASIDE


** Modules

Rust has a robust system of modules and namespaces.  Many objects, including constants, functions and modules accept visibility modifiers.  Everything is private by default, unless specified otherwise by prefixing the =pub= keyword.

Modules constitute a tree, with one root, known as the top-level module[fn:9].  The nested modules can refer to the top level module as =crate=, and their immediate[fn:10] parent module as =super=.   To access members within a module, one uses the =::= syntax borrowed from C++.

#+BEGIN_SRC rust
  pub mod thing {
	  pub const CONST: u8 = 32;

	  mod thing2 {
		  pub const CONST: u8 = 42;
		  // Warning, module private, can't see the `pub`.
	  }

	  pub(super) thing3 {
		  pub const CONST: u8 = 42;
	  }
	  pub const CONST2: u8 = thing3::CONST;
  }

  mod thing2 {
	  pub const CONST: u8 = super::thing::CONST;
	  pub mod thing3 {
		  pub const CONST: u8 = crate::thing::CONST;
		  // This is identical to `thing2::CONST`
	  }
	  pub const CONST2: u8 = super::thing::thing3::CONST;
	  // Error, thing3 is visible to `thing`
  }

  mod file_mod;			// Lives in a file `file_mod.rs`
#+END_SRC

All constructs must be either fully qualified or imported with the =use= keyword.

#+BEGIN_ASIDE
Unlike C++, the usage of =use= is not problematic.  Rust does not allow two functions with separate definitions to be imported into the same namespace, so a functional call always resolves unambiguously and the definition even for generic functions is always local.
#+END_ASIDE

The =use= keyword allows shorthand import of multiple constructs, with short-hand notation for all public items belonging to a particular module.

#+BEGIN_SRC rust
  use file_module::submod::{fun1, fun2, self}
  // Allows referring to `submod::` directly

  mod file_module;
  // The mod declaration can come after the imports

  pub mod thing {
	  use super::*;
	  // modules don't inherit parent imports
  }
#+END_SRC

Use statements are effective for the block in which they are written.  So, having use statements confined to a block is useful when one wants to avoid using fully-qualified paths[fn:12].

Rust's module system supports what's known as a re-export.

#+BEGIN_SRC rust
  pub mod file_mod;

  pub mod parent {
	  pub mod sibling1 {
		  use file_mod::func1;
	  }

	  pub mod sibling2 {
		  pub use file_mod::func1;
	  }

	  use sibling1::func1;
	  // Illegal
	  use sibling2::func1;
	  // Legal, re-export
  }
#+END_SRC

This allows programmers to present a flat structure to the end user, while retaining internal organisation.  The use keyword combined with the =as= keyword, allows renaming the values in the exported scope.

It is also a common practice to provide all the constructs that the user is likely to import in a single submodule known as a =prelude=.

Unlike the standard library prelude, it must be explicitly glob-imported.

#+BEGIN_SRC rust
  pub mod macro;

  pub mod prelude::{useful_function, macro::useful_macro, UsefulStruct};
#+END_SRC

** Overall

Rust is an average procedural language.

Compared to languages like FORTRAN and C, it is extremely difficult not to over-step the boundaries of the procedural subset; as such Rust is a poor substitute for code bases that only want to substitute a poorly supported procedural language, without adopting any aspects of either functional or OOP styles.

The experience of writing purely procedural Rust is akin to programming in PASCAL.  Despite the surgical adjustments, namely the introduction of slices, the restrictions imposed by the borrow checker contribute to a significantly slower development process as compared to C, or Go, in a purely procedural context.

As such, Rust should not be regarded as either exclusively or primarily procedural.

* Object Oriented Rust

Rust is a pragmatic OOP language.  It is as conceptually distant from a class-based OOP language (/e.g./ Java, C++) as it is from the Smalltalk family.  Rust has deliberately eschewed language features that serve to enable programmers to over-abstract and include too many indirections.  It has effective tooling for static and dynamic polymorphism.  Rust is also quite good at tracking objects properties, namely lifetimes.

It would be wise to think of Rust as an OOP language primarily, even though it is neither officially considered one by its creators, nor does it contain the typical feature set associated with OOP languages.

** Objects and Structs
Rust occupies a middle ground between traditional procedural POD sturctures and simula-style class-based structures.  For example:
#+BEGIN_SRC rust
  pub struct Complex {
	  pub real: f64,
	  pub imaginary: f64
  }
#+END_SRC
is a structure in Rust.  For example, here's how we construct an instance of this type,
#+BEGIN_SRC rust
  let number_two = Complex {
	  real: 2.0,
	  imaginary: 0.0
  }
#+END_SRC
in case there is a local variable with a suitable type, the colon can be omitted:
#+BEGIN_SRC rust
  let real = 2.0;
  let imaginary = 0.0;
  let number_two = Complex { real, imaginary };
#+END_SRC

Note that naming structures in Pascal case is strongly encouraged.  Failure to do so produces a compilation warning.

Structures don't have a well-defined layout.  This implies that most Rust code links statically[fn:13], and intrinsically means that if two structures have different names, they must be treated as different types.

Specifically, in Rust there is no subtyping.  Each variable has precisely one type.  It doesn't matter if two structures have the same layout, they can neither be implicitly converted nor cast into each other.

Instead the conversion can be done explicitly
#+BEGIN_SRC rust
  pub struct 2dVec {
	  x: f64,
	  y: f64
  }

  let v = Complex { real: 2.0, imaginary: 3.0 };
  let v = 2dVec { x: v.real, y: v.imaginary }; // x and y are private
#+END_SRC
and in later chapters we shall see a more elegant way of performing the conversions.

Each structure has visibility modifiers, that act sensibly.  Public members are visible anywhere the structure is visible, =pub(crate)= and =pub(super)= allow access in the same library and the enclosing module respectively, and by default all fields are private.

Rust supports associating methods and functions to types, called inherent implementations:
#+BEGIN_SRC rust
  impl 2dVec {
	  pub fn new(x: f64, y: f64) -> Self {
		  Self {
			  x, y
		  }
	  }
  }
#+END_SRC
Note that when defining the associated factory function =new= we have used the shorthand =Self= for the name of the type.  This is to allow efficient renaming of structure.  We have also used the fact that the arguments of the function have the correct types and names to use the short-hand notation when constructing =Self=.

If a structure has even one field that is not public, it cannot be constructed with a constructor, and the factory method if visible is the only way to construct a new instance.  This also means that the fields cannot be read or written to if private.  The type, however, can be visible, but opaque.

Inherent implementations can be used to create getter and setter methods for private fields:
#+BEGIN_SRC rust
  impl 2dVec {
	  pub fn get_x(&self) -> f64 {
		  self.x
	  }

	  pub fn set_x(&mut self, other: f64) {
		  self.x = other;
	  }
  }
#+END_SRC
At which point they can be used as follows:
#+BEGIN_SRC rust
  let real = 2d_vec.get_x();
  2d_vec.set_x(real*2.0);
#+END_SRC
Notice that the first argument in the implementation does not have a type signature.  It is also used in the prefix notation, but that is no more than syntactic sugar.
#+BEGIN_SRC rust
  let real  = 2dVec::get_x(2d_vec);
  2dVec::set_x(&mut 2d_vec, real*2.0);
#+END_SRC
is what the previous syntax implies really.

It should be noted that getters and setters are extremely rare in Rust code bases.  The reason for this is the semantics of accepting a structure as a function argument.

The inherent implementations must be defined in the same translation unit (crate, but not necessarily the same module), as the structure.  It is illegal to define inherent implementations for structures defined in other libraries/crates.

** Message passing as Traits
Rust took inspiration from Haskell in implementing a typeclass-like mechanism for polymorphism.  Instead of imposing a type hierarchy, Rust exposes a mechanism for defining an interface.  By default a new =struct= does not participate in any interface, and each structure's participation is a conscious decision made by the programmer.

Consider for a moment an interface that is not explicitly representable in C++ (until around C++ 20); namely that a type can be default constructed.  In Rust to specify that a type can be constructed with no input, one has to /implement/ the =Default= trait.

For a structure that we have defined: =Complex=, we can do so with the following construct:
#+BEGIN_SRC rust
  impl Default for Complex {
	  fn default() -> Self {
		  Self {
			  real: 0f64,
			  imaginary: Default::default()
			  // recursively call the default constructor for
			  // f64, which evaluates to 0.0
		  }
	  }
  }
#+END_SRC
To recap, we demonstrate that the type =Complex= participates in the =Default= interface.  We do so by implementing the unimplemented functions, and specifying any unspecified associated constants and types.

Anything that is true of an inherent implementation is true of a specific trait implementation.  So for example, we could implement =Default= for =2dVec= and use the constructor directly, without having to specify =pub(super)= setters.

Traits can be implemented either in the same crate as the structure, or the same crate as the trait.  So for example, if a foreign type, /e.g./  =std::vec::Vec=, does not already implement =Default= it is illegal to implement it.  This is known as the /orphan rule/.

** Pass by move
Rust is neither pass-by-copy (like C++) nor pass-by-reference (like Java).  Instead, all values are assumed to be passed by move.  Specifically for a function with the signature

#+BEGIN_SRC rust
  fn invert(mut number: Complex) -> Complex {
	  number.x = -number.x;
	  number.y = -number.y;
	  number
  }
#+END_SRC

despite the fact that the value =number= was passed as mutable, the memory locations associated to =complex1= and =complex2= aren't necessarily correlated:
#+BEGIN_SRC rust
  let complex1 = Complex::default();
  let complex2 = invert(complex1);
  // &complex1 != &complex2
  let complex3 = invert(complex1);
  // Error: complex1 is freed after the first call to `invert`
#+END_SRC
To help in this situation the trait =Clone= creates copies of objects to be used in functions that accept structures by move.

Specifically, we can implement clone in the following way
#+BEGIN_SRC rust
  impl Clone for Complex {
	  fn clone(&self) -> Self {
		  Self {
			  real: self.real,
			  imaginary: self.imaginary
		  }
	  }
  }
#+END_SRC
At which point we can modify the previous example:
#+BEGIN_SRC rust
  let complex1 = Complex::default();
  let complex2 = invert(complex1.clone());
  // &complex1 != &complex2, but complex1 is still valid
  let complex3 = invert(complex1.clone());
  // OK.
  let complex4 = invert(complex1);
  // Also fine.
#+END_SRC

So the C++ rule of three in Rust can be reduced to the creation of a factory method and implementing =Default= and =Clone=.

It must be noted, that the function call overheads when calling either the constructor function or the trait-associated function =clone=, is not always guaranteed to be optimised away.  Most =clone= implementations are recursive, and oftentimes, complex.  However, there are situations in which the bit representation of an object is the value of the object, and there is no difference between a shallow and deep copy.  Indeed our =Complex= type is just two =f64= numbers, which if copied with =memcpy= would still be a valid and /distinct/ value, which can be freed independently of the original.

To explain this to the compiler, we implement the =Copy= trait like so:
#+BEGIN_SRC rust
impl Copy for Complex {}
#+END_SRC
Note that simply marking =Complex= as copy does not involve implementing any function.

After this implementation, we can remove =Clone= as copies shall be done automatically by the compiler.

Rust does not support sub-typing for structures, but it does support trait pre-requisites.  As such, if =Complex= did not implement =Clone= it would not be =Copy=.

This is not to say that each instance of pass-by-copy inserts or desugars to an insertion of =Clone::clone=.  If a value is marked as =Copy=, the cloning is done by replicating the bit-pattern and not recursively calling =clone=.

** Polymorphism
*** Trait-associated functions, turbofish

We are now equipped to tackle the question of how Rust achieves polymorphism.  There are several mechanisms that work concurrently and all of them revolve around traits.

Let us first start by noting that there can be only one free-standing function for any given name.   This extends to inherent implementations.  Though an inherent implementation can have the same name as a freestanding function:
#+BEGIN_SRC rust
  fn hello() {
	  println!("hello")
  }

  impl Complex {
	  pub fn hello() -> {
		  println!("hello again")
	  }
  }
#+END_SRC
there can be only one inherent implementation with a given name.  A trait can also only be implemented once.

Since both the trait-associated and inherent implementations share the call syntax, whenever there may be ambiguity Rust requires the programmer to disambiguate manually:
#+BEGIN_SRC rust
  let clone = Object::clone(&object); // inherent
  let clone = <Object as Clone>::clone(&object); // associated to the `Clone` trait
#+END_SRC
the syntax =<Type as Trait>::method= is sometimes called the turbofish.

A function associated to a trait can be called only if that trait is in scope.  The trait =Clone= is imported as part of the standard library =prelude=, but other traits must be imported manually before use.  If two traits have an associated function of the same name, each =.method= call must be rewritten as =<Type as Trait>::method= turbofish.  This is technically a form of static polymorphism, but not particularly interesting.

*** Generics
**** Structure and function basics, trait bounds
Rust supports generics via templates.  Like in C++ both structures and functions can be made generic.  What this means is that for each instance of a generic structure template, a new structure definition is created.  These structures are considered distinct types in all but generic functions.
#+BEGIN_SRC rust
  struct Complex<T: Copy + Default> {
	  real: T,
	  imaginary: T
  }
#+END_SRC
In this example we specify that =Complex= is a generic structure parameterised by a single type =T=, that can only be a type that is both trivially =Copy=-able and =Default=-constructable.  We know that if =Complex<Sometype>= is a valid type, then =Sometype= must implement both traits.   In C++, this isn't always the case, and usage of C++ concepts is complicated enough that these cases are the minority.

Methods for generic structures must also be generic.
#+BEGIN_SRC rust
  impl<T: Default + Copy> Complex<T> {
	  pub fn new(real: T, imaginary: T) -> Self {
		  Self { real, imaginary }
	  }
  }
#+END_SRC
Note that we must provide constraints which are at least the same or more constraining than the ones that we have provided in the structure definition.  So for example adding =T: Default + Copy + PartialEq= to the =impl= generic arguments, would entail that the generic functions defined in that block are only defined if =T= satisfies =PartialEq= in addition to the constraints imposed in the structure definition.

#+BEGIN_SRC rust
  impl<T: Default + Copy + PartialEq + Eq> Complex<T> {
	  pub fn is_default(&self) -> bool {
		  self.real == T::default() && self.imaginary == T::default()
	  }
  }
#+END_SRC
In this example, we rely on the fact that if a type =T= implements both =PartialEq= which defines the equality operation and =Eq= which states that for all valid values of =T= an equality comparison has all the usual properties, and always yields a boolean value, then we can ask of =Complex<T>= if it is the =default=.

**** Blanket implementations
The above example is for illustration purposes only; most new programmers in Rust will fall into a few common traps which we shall mention here, and fix later.

Specifically, we assume that the implementation of =Complex<T>::default= is recursive and comprises the defaults of =real= and =imaginary=.  This is true assuming no other code exists, but may not be true in general.  In fact, assuming the code that we have presented as examples is the only code that there is, the concept of =Complex<T>::default= is not defined.  So we should provide an implementation for that:
#+BEGIN_SRC rust
  impl<T: Default + Copy> Default for Complex<T> {
	  fn default() -> Self {
		  Self {
			  real: T::default(),
			  imaginary: Default::default(), // Type T inferred, identical to above
		  }
	  }
  }
#+END_SRC
This is called a /blanket implementation/, as it covers more than one type =T= in this set.  Blanket implementations are useful, but not as much as one might expect at first glance, because unfortunately, trait implementations that can overlap either now or hypothetically in the future, are both covered by a blanket implementation there is a conflict that cannot be resolved at present.

In this example we must note that if we had omitted the =Default= trait bound in the definition of =Complex<T>= we would still have a sound set of functions.  It is only sensible to consider if =Complex<T>= is the default if said default is defined.  But due to the constraints inherent in Rust's trait system, we would not be able to define =is_default= as easily, so we have chosen to require that the =T= be =Default= for all valid =Complex<T>= types.  We shall see later how this could be done with more sophisticated =where= clauses.

#+BEGIN_aside
Because of the way that this system is set up, we can always know for certain where the function called in each particular case is defined.  One knows that a function can only be defined once, and never overloaded, so a regular expression search is all one needs to find where a particular function is defined.
#+END_aside

**** =From= and =Into=

One of the most important applications of generic functions is in conversions between types.  In general only numerical types and pointers can be cast using the =as= keyword.  Every other kind of conversion is done via either =From=, =Into= or =AsRef=.

These traits cover the different possible conversions scenarios, so it is worth exploring them.

=From= should be the first trait to consider.  It simply states that two types can be infallibly converted into one another.   A good example is considering how we can convert an array of floating point numbers into =Complex<f64=.

#+BEGIN_SRC rust
  impl From<[f64;2]> for Complex<f64> {
	  fn from(value: [f64; 2]) -> Self {
		  Self { real: value[0], imaginary: value[1] }
	  }
  }
#+END_SRC

This can be invoked like so
#+BEGIN_SRC rust
  let complex = Complex::from([1.0, 0.0]);
#+END_SRC

Here we can demonstrate the importance of providing blanket implementations.  Suppose we had a function which accepts =Complex<f64>= as an argument, /e.g./
#+BEGIN_SRC rust
  fn rotate_90(number: Complex<f64>) -> Complex<f64>;
#+END_SRC
we can now invoke this function in a way which closely mimics implicit conversions:
#+BEGIN_SRC rust
  rotate_90([1.0, 0.0].into())
#+END_SRC
This all because for all types =A=, and =B= such that each =B= implements =From<A>= the inverse trait =Into<B>= is implemented for each =A=.  As such, one gets two trait implementations at the cost of one.  Unfortunately, implementing =Into<B>= for some =A= does not automatically implement =From<A>= for =B=, at least not yet, so one should always consider implementing =From= if possible.

**** Custom traits

The Rust programmer is encouraged to introduce traits.  A typical trait definition is akin to an interface in Java.  Traits can have associated types, associated constants, and associated functions.  Each can have a default implementation that can also be overridden for each concrete type.
#+BEGIN_SRC rust
  pub trait HaveItAll {
	  pub const DEFAULT_CONST: u32 = 0;
	  pub type DefaultType = u32;
	  pub type MustBeClone: Clone;
	  pub const CONST: MustBeClone;

	  fn get_const(&self) -> Self::MustBeClone {
		  Self::CONST
		  // Can override
	  }

	  fn must_implement(&self, other: Self::DefaultType) -> Self::MustBeClone;
  }
#+END_SRC

In Rust a trait can require the implementation of another trait known as a /supertrait/.  Trait inheritance is the only kind of inheritance that Rust supports.
#+BEGIN_SRC rust
  pub trait CopyExtension: Clone + Debug {
	  fn copy(&self) -> Self {
		  println!("{:?}", self);
		  self.clone()
	  }
  }
#+END_SRC




**** Ownership, and =Drop=


Rust is a RAII language.  This coupled with the borrow checking rules implies that one can safely de-allocate any structure as soon as it reaches the end of the scope in which it is defined.  But this is only true of simple structures, those that implement =copy= as some structures may need to perform complex housekeeping to safely stop existing.

In Rust, the role of destructors is filled in with the =Drop= trait and the associated function =Drop::drop=, using its fully qualified name.  The function is called recursively for types that implement it, and for types that contain types that implement recursively.

#+BEGIN_SRC rust
  struct HasDrop;

  impl Drop for HasDrop {
	  fn drop(&mut self) {
		  println!("Dropping HasDrop!");
	  }
  }

  struct HasRecursiveDrop {
	  one: HasDrop,
  }

  fn main() {
	  let _x = HasRecursiveDrop { one: HasDrop };
  }
#+END_SRC

In this example, even though technically there isn't an explicit implementation of =Drop= for =HasRecursiveDrop= the =<HasDrop as Drop>::drop= function shall be called and the =dropping HasDrop!= message shall be printed.

This lends itself to the notion of ownership.  A field in a structure is owned by that structure.  The structure is responsible for both creating and de-allocating the field.

This however means that each object must have precisely one owner.  And all objects that exist within the program must be traceable to a few objects created in =main.rs= either directly or indirectly.   Instead of having a class hierarchy, Rust opts to have an object hierarchy.

In Rust, this allows one to effortlessly use types that manage resources externally.  This leads to some quirks, that should be noted.
For example, if a value is returned from a function it must be bound to a variable, otherwise its destructor is called immediately.

#+BEGIN_SRC rust
  let _keep_alive = SomeStruct::long_running_task_handle();
#+END_SRC
in such circumstances it is common to see the following construct.  Also note the underscore in the =_keep_alive=; without it the static analyser will warn about =keep_alive= being unused.  So be cautious of naming your variables, including fields with underscores prefixed or postfixed.

**** =AsRef=, =Deref= and Smart pointers

The reason why we needed to cover ownership was to introduce the concept of a smart pointer.

To cover ground where ownership hierarchies are unsuitable, Rust borrowed an idea from C++11.  Namely to create special wrapping types known as smart pointers whose construction is meant to replicate manual memory management patterns on types, without the programmer writing boilerplate.

=Box<T>= is a unique pointer to a heap-allocated =T= that de-allocates the heap memory when it goes out of scope.  =Rc<T>= is a reference counted pointer that is used when multiple objects need to share a resource.  =Arc= is atomically-reference counted which can be used when the objects referencing the shared object are in different threads.

The mechanism by which the use of these smart pointers is practical is known as dereference aliasing.  Implementing the trait =AsRef<T>= signals to the programmer and the compiler that the object in question can give a reference to a valid structure of type =T=.  For example,
#+BEGIN_SRC rust
  pub struct Zoo {
	  ape: Ape,
	  crocodile: Crocodile,
	  parrot: Parrot,
  }
#+END_SRC
can reasonably provide implementations for =AsRef<Ape>=, =AsRef<Crocodile>= and =AsRef<Parrot>=, even though this usage is discouraged[fn:14].

Implementing the trait =Deref= signals to the compiler that the object should be regarded as a pointer to the type =T=.  Specifically, in
#+BEGIN_SRC rust
  let boxed_parrot = Box::new(Parrot::default());

  boxed_parrot.parrot_method();
#+END_SRC
because =Box<Parrot>= implements =Deref= with the associated type =Target= set to =Parrot=, or in Rust notatoin =Deref<Target=Parrot>= the call to the function =parrot_method= is unambiguous, and no further indirection is needed.

#+BEGIN_aside
While it is tempting to use these traits to create a form of object inheritance, this is strongly discouraged.  The =Deref= and =AsRef<T>= traits should only be implemented if one truly wishes to represent a pointer to a type, as this is the intention being communicated.
#+END_aside

*** Trait objects

The final and most delicate mechanism is late binding.

Rust supports dynamic dispatch via type erasure and so-called fat-pointers[fn:15].  Because the sizes of all implementations of a certain trait are not guaranteed to be identical, one must do explicitly in Rust what Java does implicitly.  Namely all dynamically dispatched objects in Rust must be heap-allocated and managed via borrow/smart pointer.

The most common application is a heterogeneous collection of objects that implement the same trait, in error handling, but these objects can be used directly by borrow, consider the trait defined as
#+BEGIN_SRC rust
  trait HasNorm {
	  fn norm(&self) -> f64;
  }

  impl HasNorm for Complex<f64> {
	  fn norm(&self) -> f64 {
		  self.real * self.real + self.imaginary * self.imaginary
	  }
  }


  impl HasNorm for Complex<f32> {
	  fn norm(&self) -> f64 {
		  (self.real * self.real + self.imaginary * self.imaginary) as f64
		  // Demonstration purposes only
	  }
  }
#+END_SRC

we can define a polymorphic function that can accept either a reference to =Complex<f64>= or =Complex<f32>=, or any type that implements =HasNorm= as follows:

#+BEGIN_SRC rust
  fn modulus(value: &dyn HasNorm) -> f64 {
	  let norm = value.norm();
	  norm.sqrt()
  }
#+END_SRC

This approach is different to /e.g./
#+BEGIN_SRC rust
  fn modulus<T: HasNorm>(value: &T) -> f64 {
	  let norm = value.norm();
	  norm.sqrt()
  }
#+END_SRC
in the following way.  The dynamically dispatched function exists in one place.  If for example, we have \(n\) functions defined as dynamically dispatched, and \(m\) implementations of =HasNorm=, then there are \(n\) functions and \(m\) vtables.  By contrast each generic function is instantiated for each implementor of =HasNorm=.   We have a multiplicative explosion of code paths, a reduction in code locality, in exchange for potentially[fn:16] better performance if the virtual calls can be converted to different code paths.

There are situations in which trait-object based code is clearer, particularly if the concrete type is too verbose or necessitates a large number of trait bounds to be repeated.  More on that later.

Dynamic dispatch imposes its limitations.  Type erasure means that only the information about the objects implementation of a particular trait can be used.  For example, if the object was converted to =&dyn HasNorm= and there is neither a supertrait nor a blanket implementation of =Debug= for all implementors of =HasNorm=, then an said object can no longer be printed.

#+BEGIN_aside
One example of inconvenience imposed by type erasure is the =std::io::Error= type.  It wraps a =Box<dyn std::error::Error>= trait object, as a result of which a =std::io::Error= objects cannot be cloned.  While there are ways of making trait objects =Clone= almost all of them involve changing the trait, which in case of =std::error::Error= would result in almost all Rust code being broken.
#+END_aside

** Encapsulation
*** Invariance at construction
Rust provides a robust set of interlocking features that make it an excellent language to write encapsulated code.

We have noted earlier that it is exceedingly rare to see =getters= and =setters= in Rust, and even then more often than not, as a result of needing to manipulate Rust objects from a different programming language via a Foreign function interface (FFI).

This is because the borrow checker and immutable-by-default variables impose enough restrictions to preserve structure invariants by other methods.  Because one does not have inheritance, one has to choose composition.  Because most values are passed by move and immutable, one is encouraged to construct new values instead of mutating the old ones in place.

Technically speaking the only other place where Rust getters and setters are used in earnest are in the builder pattern, but even then they are used as syntactic sugar for constructing a new value, rather than for the purposes of preserving an invariant.  Because it is easier to construct a new immutable value, the focus in Rust has shifted away from imposing instance invariants towards type invariants enforced at construction and propagated by immutability.

To demonstrate the difference in philosophy consider the following example.  When implementing a builder for a type in Rust, one is ordinarily accepting =self= by move and returning a new value.

This permits a pipeline style that was popularised in Java with the introduction of anonymous functions, and in C++ with the introduction of ranges.
#+BEGIN_SRC rust
  let thing: File = OpenOptions::new()
	  .read(true)
	  .open(path)
#+END_SRC

Unfortunately, there are situations in which shared data indeed needs to be mutated.  For example the database in a server must be mutable and able to respond to requests handled by, potentially, different threads.

*** Type state
Additionally, thanks to strict typing, lack of subtyping, and a low overhead to establishing throwaway datatypes, Rust encourages programmers to utilise the type-state pattern.

The idea is simple, each state of the system is encoded as a type.  For example, if one needs to establish a handshake process with a web-based service, and this involves reaching a server, obtaining a =session_cookie=, sending one's =public_key= verifying the server's signed message, the type state representation of that process would look like this
#+BEGIN_SRC rust
  pub struct Start {
	  public_key: PublicKey,
	  server_address: ServerUrl,
  }

  struct ServerReached {
	  public_key: PublicKey,
  }

  struct ServerReplied {
	  public_key: PublicKey,
	  session_cookie: SessionCookie,
  }

  struct PublicKeySent {
	  public_key: SentPublicKey,
	  session_cookie: SessionCookie,
  }

  struct ServerSentSignedMessage {
	  public_key: SentPublicKey,
	  message: ServerMessage,
	  session_cookie: SessionCookie,
  }

  pub struct ServerMessageWasCorrect {
	  public_key: SentPublicKey,
	  message: VerifiedServerMessage,
	  session_cooki: SessionCookie
  }
#+END_SRC

with all the state transitions codified either as freestanding functions, or inherent implementations, the advantage of this approach is that illegal state is unrepresentable, and only specific state transitions are allowed.  One controls the state transitions and one can guarantee that the intermediate states do not leak through the program.  Such a type-state module is largely a self-explanatory process diagram, that happens to do the right operations in the right order to reach the server in question.

*** Interior mutability

In Rust, immutable borrows aren't really immutable, but encapsulated.  By that I mean that =RefCell=, =Mutex=, =RwLock=,  the numerical types in =std::sync::atomic=, all allow mutating the state of objects through an immutable borrow.  The logic behind this is that if the programmer knows what they are doing, they can safely mutate shared state.  The preferred way to do this, is by relying on the programmers of the Rust standard library or any of the crates on crates.io, to have ensured that mutation via the public API of =Mutex= does not produce undefined behaviour, or errors due to concurrent modification.

The difficulty of properly syncrhonising state in Rust is reduced to the problem of picking the correct interior mutability primitives.  While it is in a way significantly simpler than managing mutual exclusion logic manually, still concurrency requires some subtle thought.  While it is no longer as easy to produce a concurrent modification error by modifying a collection while iterating over it, it is still possible to cause a deadlock.

Similarly, while smart pointers proect one from causing undefined behaviour, leaking memory in Rust is just as easy as in many other non-garbage collected languages.



** Conclusion
As we have hopefully demonstrated Rust is a capable OOP language, despite eschewing many of the common design choices of class-oriented OOP languages, namely C++ and Java.  Given the static typing and preference for monomorphic dispatch, Rust is fundamentally different from languages with an object-first mentality, such as JavaScript and Smalltalk and only some design patterns from these languages would translate into Rust.

Rust is a better OOP language than it is a procedural language, due to the fact that many of its design decisions were a direct reaction to some of the problems that are apparent in modern class-oriented programming.

It is a language that supports OOP, rather than encourages it, in the sense that it does not commit to a wholly principled view.   However, the paradigm whose goals align more with those of Rust is OOP, and other paradigms are supported to a lesser extent.






* Functional Rust
Functional programming is often touted as Rust's most prominent inspiration.  While Rust can be considered to have the larget amount of functional-inspired features of the mainstream languages, the support for the functional programming style is about on par with its support of the procedural style.

** Algebraic data types

Rust as we have demonstrated before supports =struct= declarations, which in the functional programming terminology are known as /product/ or /record types/.

*** Overview
Rust also supports anonymous positional records known as tuples,
#+BEGIN_SRC rust
  let tuple: (&str, [u8; 5]) = ("hello", b"world");
#+END_SRC
named positional records, known as =tuple structs=:
#+BEGIN_SRC rust
  pub struct Both<T, E>(T, E);
#+END_SRC
and named nominal sum types, known as =enums=:
#+BEGIN_SRC rust
  pub enum Either<T, C> {
	  TupleVariant(T),
	  StructVariant {
		  variant_field: C
	  }
  }
#+END_SRC
which can all be generic using the monomorphisation mechanism described in the OOP chapter.

Interaction with these types is facilitated by pattern matching via either the =match= keyword, the =if let= and =while let= conditional and loop keyword variants, as well as destructuring using the =let=  or in function signatures.

For now let us consider how one would access each individual value stored inside the tuples, tuple structures, and =enum=-erations.

#+BEGIN_SRC rust
  let tuple = ("hello", b"world", 3, 4, 5, 6);
  let (first, _ , third, _ , fifth, _) = tuple.clone(); // We need to clone, because a `String` is not a primitive type
  let first: &str = tuple.0;			 // Short-hand syntax. Useful when ignoring
  let first_clone = first.clone().to_owned(); // So-called owned `String`.
#+END_SRC

In this example we mix the positional destructuring as well as the /dot/ syntax for accessing wrapped structures.  Typically tuples are needed when more than one value should be returned from a function and immediately processed.  Tuples should be regarded as anonymous structures, and accordingly, used only when the positions of objects can alone convey the meaning.

#+BEGIN_SRC rust
  struct NamedTuple(pub u32,  pub u16);
  // The structure names are ignored. This is to encourage using braced
  // structs if the name matters.
  let NamedTuple(first, second) = NamedTuple(32, 44);
  // Now the names are bound, and since they are both primitive, can be
  // copied out.
#+END_SRC

Tuple structures are very rarely used with more than one argument.  They are a convenient short-hand for wrapping other structures, although they can be used to differentiate tuples /with different names/ but identical types.

Named tuples, also known as /tuple structs/ are almost exclusively used to wrap and decorate foreign types, as their utility is primarily in preventing types with different structure from behaving identically.


*** Enumerations
#+BEGIN_SRC rust
  pub enum Request {
	  Process(&str),
	  Transact{
		  source: Id,
		  destination: Id,
		  transaction: Box<Request> // Recursive data must have indirection
	  },
	  Expunge,					// If no data, can omit parens
	  Close = 4,					// Explicitly assign representation as integer to this enum
  }

  match {
	  Request::Process("hello") | Process("Hello") => println!("Hello"),
	  Request::Transact{ source, destination, transaction} => {
		  println!("{source} to {destination}");
		  transaction.execute()
	  },
	  _ => println!("Either close or expunge, don't know which")
  }
#+END_SRC

Enumerations are the main reason why some believe Rust to be a functional, or a functional-inspired language, as enumerations allow one to record type information at runtime and defer control flow.  Specifically, in a traditional OOP language, if one wants to have a heterogeneous list of values, they have only one choice, the equivalent of =Vec<Box<dyn SomeTrait>>=, which is relatively inexpensive, and often does /not/ involve a virtual call resolution.

But there is a third option, in case one does not want to model the differences in behaviour associated to the type, but rather /ad-hoc/, then we have the option of creating an =enum= which must ahead of time, declare the types which can be included in that structure.

This relieves us of many limitations associated to trait objects, namely our inability to clone without proper setup, and a few other problems are easily mitigated.  An =enum= is a distinct type, which works as a =union= does in a language like C or C++.  Unlike those languages, an =enum= already contains information about which variant it is.  This information is usually stored as a number, but one can control that with a compiler attribute.  In the example above, the =Process= variant is stored with the value =0=, and all variants except =Close= are numbered sequentially.  =Close= is set to =4= which means that the tag value of =3= is never assigned.

Tagged enumarations are always safe to operate on, at the cost of wasting typically an extra machine word.  Clippy, the static analysis tool will warn about wildly diverging enum sizes, and suggest using a =Box= to heap-allocate the larger variant, but this is not always good advice, which is why it's relegated to a linter.

Unlike OCaml and Haskell, the Rust programming language cannot infer if the type can be safely inlined, so recursive enumerations must always refer to themselves with a type that stores them elsewhere.  This requirement has far reaching consequences limiting Rust's ability to support a pure functional or semi-imperative functional approach.

Enumerations are used extensively in Rust.  For example, of the two mechanisms of error propagation, the one that the user is meant to be able to control involves the =std::result::Result=, enumeration.  Most fallible operations use =std::option::Option=, which is yet another simple enum.

*** Option

The most important[fn:17] =enum= is the built-in =Option= type.  The technical term for =Option= is a monad.  To those familiar with that concept, Rust is disappointing, given that this is the only[fn:18] kind of monad that Rust /can/ support, and its type system is somewhat restrictive.  However both the extent to which that one type can influcence the usability of Rust and its prevalence are sights to behold.

Option dictates how any fallible operation in Rust is to be conducted, in the absence of any other facilities.  If you want to build a layer that works without a heap allocator; or without any external dependencies to run inside a virtual machine, being miserly with space?  =Option= is the best choice for these circumstances.

#+BEGIN_SRC rust
  let posibly_overflowing: Option<u64> = u64::MAX.checked_add(u64::MAX); // Contains None
#+END_SRC

The above example demonstrates a typical application: the unsigned integer addition can fail for one reason and one reason only, if the numbers are too large to fit into memory.   As a result, libraries will signify the failure of such an operation with an =Option= type, which must then be used with an explicit handling of the =None= variant.

As such it is somewhat inconvenient to add more than number that way:
#+BEGIN_SRC rust
  u64::MAX.checked_add(u64::MAX).checked_add(u64::MAX);
  // This expression does not compile, because the `Option` cannot be added to another number
#+END_SRC
While this inconvenience can be considered a problem in most other languages, the Rust approach is to make problematic statements complicated.

In this particular case, one must be cognisant of the fact that the addition can (and in this case /will/) fail.
#+BEGIN_SRC rust
  let failed_addition = u64::MAX.checked_add(u64::MAX);
  match failed_addition {
	  Some(_) => unreachable!(),
	  None => println!("Yep, adding two maximal values should overflow")
  }
#+END_SRC
Here we've used the =unreachable= macro, to signal to the compiler, that we can guarantee that the pattern =Some= with any form of data is not only not handled, but impossible.

In circumstances such as this (with an important distinction), it is common to see the usage of =unwrap= and =expect=, which are correspondingly designed to handle the opposite situation.

#+BEGIN_SRC rust
  let normal_addition: u64 = 0.checked_add(1).unwrap().checked_add(2).unwrap();
#+END_SRC
While =unwrap= is easier to use, it is much more common to use =expect=; as it allows you to specify the invariant and explain why a particular =Option= will result in the correct value:
#+BEGIN_SRC rust
  let better_addition: u64 = 0.checked_add(1)
	  .expect("0 + 1 == 1 < u64::MAX")
	  .checked_add(2)
	  .expect("1 + 2 == 3 < u64::MAX");
#+END_SRC
This is somewhat verbose, but well warranted in mission critical code.

One, of course, doesn't always have the luxury of knowing ahead of time, which of the two possibilities is going to occur.  In a number of cases, nothing sensible can be done, except printing a message and exiting the program immediately.  In these cases =expect= is used:
#+BEGIN_SRC rust
  fn add(num: u64, num2: u64) -> u64 {
	  num.checked_add(num2).expect("The function `add` was called with overflowing addition. Execution cannot continue. Exiting")
  }
#+END_SRC
If the function is called with arguments whose addition overflows, the program halts immediately printing the error message.  This pattern is called a *panic*.

The =expect= method is a generic method associated to =Option=, that has for all intents and purposes the following approximate implementation
#+BEGIN_SRC rust
  impl<T> Option<T> {
	  fn unwrap(self) -> T {
		  match self  { Some(value) => value, None => panic!() }
	  }
	  fn expect(self, message: &str) -> T {
		  match self {
			  Some(value) => value,
			  None => panic!(message)
		  }
	  }
  }
#+END_SRC
Note the usage of the =panic= macro.

#+BEGIN_aside
At this point it is worth asking what would happen if a branch containing =unreachable= is ever executed.  At first glance in both cases the program should stop executing and print an error message.  And indeed this is what happens on a default (debug) build.

However, there is a difference in intention.  A =panic= is a situation in which the program cannot sensibly recover.  An =unreachable= situation is a programmer error, in which it is not safe to continue execution.  As such it is the programmer's responsibility to ensure that an =unreachable= expression is truly not reachable, with tests.  Once that is asserted, however, the programmer may well expect the compiler to optimise away all branches associated with =unreachable= code.

As such, a =panic= will always exit the program, however reaching an =unreachable= statement in a release build is *undefined behaviour*.
#+END_aside

#+BEGIN_aside
It should be noted that to a functional programmer, any function that contains =expect=, =unwrap=, =panic= or a faulty =unreachable= should seem problematic.  In Haskell, such functions should be annotated with a monad, that indicates that a subtree of function calls may result in a panic.  Rust offers no such facilities, as that would increase the verbosity of the programming language further.

The =clippy= static analysis tool has a lint, which prevents panics in the code.  However, that tool must be enabled by default, and downstream users may mask panics with an =allow= directive.   This might seem like it defeats the purpose, but in most situations, this is sufficient.
#+END_aside

One important aspect of =Option= is that it is highly optimised.  While normally, one must always reserve a machine word to handle an =Option= value, in some situations, =Option= can take up as much space as a =union= would in C.

Specifically, this is known as the niche optimisation.  If a type included in the =Option<T>='s generic argument has been marked as not accepting all possible values, but instead being restricted to for example being non-zero, as for example =NonZeroU64=, =Box= (in general Rust pointers are never =null=), and custom types; =Option= may use one of those values to represent the =None= variant.   As such it is always preferable to represent a C-style[fn:19] nullable pointer as a Rust =Option<Box>=.

***  =Result=

Result is a minor extension of =Option=.  For all intents and purposes, the definition of =Result= can be regarded as
#+BEGIN_SRC rust
  pub enum Result<T, E> {
	  Ok(T),
	  Err(E)
  }
#+END_SRC

Note the absence of any trait requirements to be wrapped in an =Err= variant.

It is typical to see the =Result= in situations in which more than one thing can go wrong, in a chain of interactions.  It is also possible to mix =Option= and =Result=, but often by converting the =None= variant into a proper =Result=.

One may ask what is the important difference in between =Option= and =Result=, and why wouldn't =Result<T, ()>= be equivalent to an =Option=.

Indeed, structurally these types would be identical.  And indeed, many of the optimisations which pertain to =Option=, are applied to to =Result= if its =Err= variant carries no data.  So why then do we have a separate =Option= type?

It turns out that while structurally the concepts are similar, the intention being communicated is different.  A =None= variant isn't usually an error.  A user not specifying an optional parameter at the command-line is hardly an error and hardly needs to be treated as such.  Not finding a particular key in a database is different to not being able to execute any query on the database because of incorrect credentials.  Case in point:

#+BEGIN_SRC rust
  match query_result {
	  Ok(Some(user_id)) => user_id.record(),
	  Ok(None) => log::debug!("Found nothing"),
	  Err(e) => log::error!("Database is down, possibly ran out of disk space, please contact admin")
  }
#+END_SRC

*** Defining error types
However, there is a difference in intention.  In the above example of checked addition, it is sensible to define an arithmetic error enumeration:

#+BEGIN_SRC rust
  #[non_exhaustive]
  pub enum ArithmeticError {
	  Overflow,
	  Underflow,
	  DivZero,
	  LogNegative,
	  // ...
  }
#+END_SRC

which must always be handled explicitly and during each operation.  It would also be sensible to attach data to each variant, /i.e./ to at least know why specifically did the operation overflow.  To do that, though, one has many options, the most general and therefore ergonomic of which is to define the error variant as follows:

#+BEGIN_SRC rust
  pub enum ArithmeticError{
	  Overflow{
		  lhs: Box<dyn Display>,
		  rhs: Box<dyn Display>,
		  line: usize
	  },
	  Underflow {
		  lhs: Box<dyn Display>,
		  rhs: Box<dyn Display>,
		  line: usize
	  },
	  DivZero {
		  lhs: Box<dyn Display>,
		  line: usize
	  },
	  LogNegative,
  // ...
  }
#+END_SRC

This can be considered very good in terms of detail, and this kind of arithmetic error can be applied to external numerical types, for example =Decimal=, and or one of many binary coded decimal types.  The only requirement is that the left-hand-side and the right-hand-side be printable and that a line number be provided.

While for some kinds of code, such =ArithmeticError= types are useful, in most situations we know which type was operated on and we can rely on Rust generics to carry that information with us:

#+BEGIN_SRC rust
  pub enum ArithmeticError<T> {
	  Overflow {
		  lhs: T,
		  rhs: T,
		  line: usize
	  },
	  Underflow {
		  lhs: T,
		  rhs: T,
		  line: usize
	  },
	  //...
  }
#+END_SRC

This structure is far more useful, because we can then conditionally implement =Display= for it if =T: Display=, use =Debug= and do a great many other things.

The simplest error enumeration is by far the least restricting: no data needs to be carried, as such, the entire enumeration can implement =Copy=.

In the second case, the entire error is easy to mark in one's return type, and is very general.  But because of the generality, one cannot (for example), implement =Clone= for this type, and =Debug= would have to call the =Display= implementations of the underlying types.  Plus, each =Box<dyn Display>= is really a two-word fat pointer.  Most types for which it would be used fit into a single machine word.

The generic error bloats the compiler output and the executable.  Furthermore, it would require the user to explicitly annotate the return type of the error.  The only place where that wouldn't be a problem is the library implementing the checked arithmetic operations, by being generic.

Finally, the astute type-level programmer, would find that the =ArithmeticError= is really, in all cases, accepting of data types that should not appear in arithmetic to begin with.  One can conceivably construct =ArithmeticError::Overflow= for types in which addition is not defined.  Setting explicit trait bounds without introducing more than one generic type parameter is also not possible, resulting in an enumeration that has as many type parameters as there are variants, making returning such a type exceedingly problematic.

If type level soundness is important, it would be much better to have separate structures which have the appropriate trait bounds:
#+BEGIN_SRC rust
  pub struct Overflow<T>
  where
	  T: core::ops::Add<T>
  {
	  lhs: T,
	  rhs: T,
	  code_line_number: usize
  }
#+END_SRC

and conditional implementations for cases where =T= would implement =Debug= and =Display=, =Clone= if types are =Clone= and =Copy= if the types are lightweight.  But in that case, if more than one arithmetic operation can fail, and for more than one type, one would still have to generate a bespoke enumeration.

Alternatively, one may be tempted to use a =Result<T, Box<dyn std::error::Error>>=, which in principle should provide enough facilities for sensible error handling.  The sad reality is that at this point there are very few things that one can do to the =Err= variant to sensibly recover.  In fact one cannot even =Clone= such errors, as is the case with =std::io::Error=.

This is a fundamental problem in the design of =std::error=, and it cannot be fixed.  There are few reasons why at this point it wouldn't be sensible to simply print out the error and continue (or panic).

There are numerous libraries that aid in designing error variants.  However, one is always faced with the following dilemma: errors are either too much work to instantiate, or too much work to handle.

As such there is a soft-guideline: errors in libraries should be easy to handle, but difficult to construct; and errors in user-facing code should provide extra context, but make no attempt at recovery.  The result is a considerable shortfall in what Rust is capable of and what the reality of error handling.

Yours truly has a vested interest in correcting this.

**  Type system

*** Strict typing and type inference

Rust follows an ML-style strict typing system.  While we have already touched upon some of the corollaries of that system in the procedural chapters, we must at some rate also describe how that fits into the functional programming paradigm.

Like ML, the type system is restrictive enough so that in most circumstances, one does not need to annotate any types at all.  Unlike ML, this doesn't extend to function signatures.  This, while somewhat annoying is a necessary addition to make Rust easier to manage at large, and permits a more generic system.  For example, unlike ML, it is possible to overload the numerical addition: =3_u32 + 2_32= is a different function to =3_u64 + 2_u64=, which is different still from =MyType(1) + MyType(2)=.

There are a few reasons for this departure.  Rust is a systems programming language.  This means that one has to be precise with the type of integer that one uses, as it is not possible to simply delegate that information to the compiler.  True in /most/ situations it is best to use the native register-width integer, and it is /sometimes/ better to use arbitrary precision unsized integers too.  However, the choice to do so should be up to the programmer and not the compiler.

As such it was necessary to consider whether strict typing was more important than the annoyance of having defined different integer-width operators.  Making an ad-hoc built-in distinction was ruled out, even though languages like Java happily live in such a world, for Rust it was decided not to be the case.  Another option would have been to enhance the macro system to be type-aware, which would then overshadow the generics, and complicate interactions between libraries.  As such it was decided to introduce the trait system.

We have motivated and included the trait system in the discussion of Rust as a primarily OOP language, and while it is in truth no different to the interface system of /e.g./  Java, it is not, by any means exclusively similar to that.  For this purpose we shall consider it in the functional chapters also.

Rust's trait system is largely inspired by the type class system of Haskell, but it is not the same, due to limitations of the Rust type system.  As such many solutions to many problems couldn't be copied, and had to be adapted.

*** Traits as type classes

A trait can be regarded very similarly to a type class in lower kinded situations.  We have already discussed the simplest traits: =Clone= and dependent traits =Copy=, with additional deeper discussions of =Default= postponed to later chapters.  In this chapter we shall focus on the strictly mathematical =PartialEq=, =Eq=,  and later =PartialOrd= and =Ord= traits.

*** =PartialEq=

So what is =PartialEq= for?  It is the "legwork" trait for interactions with the ==== operator.  Implementing this trait implies implementing the =eq= function and optionally overriding the =ne= method.  This is what an example implementation looks like for the =Complex<T>= type:

#+BEGIN_SRC rust
  impl<T: PartialEq> PartialEq for Complex<T> {
	  fn eq(&self, other: &Self::Rhs) -> bool {
		  self.real == other.real && self.imaginary == other.imaginary
	  }
  }
#+END_SRC
By construction unless we implement =ne= the default implementation associated to this trait is a strict inverse.  A =Complex= is either equal or it is not.

Upon first glance, this relation has the following properties:
1) for all =a=, =a.eq(a)=;
2) if =a.eq(b)= then =b.eq(a)=;
3) if =a.eq(b)= and =b.eq(c)= then =a.eq(c)=;

Given that the Rust compiler has no way of checking that this rule holds, we must manually signal to the compiler that our implementation is a full equality relation by implementing the marker trait =Eq=, similar to how we needed to implement =Copy=, if the =Clone= was a bit-wise copy of the object.

We reflect the fact that the equivalence relation properties only hold if they hold for the underlying type =T=, if those properties hold for values of type =T=, with the following implementation:

#+BEGIN_SRC rust
  impl<T: Eq> Eq for Complex<T> {}
#+END_SRC
which would implement =Eq= for =Complex<u64>= but not, for example for =Complex<f64>=.

So what this means is that a regular programmer is allowed to do comparisons with floating point numbers, via the equality operator, but is notified of the fact that they cannot rely on the fact that the equivalence relation defined this way is a proper equivalence relationship.

This is a vast improvement over the interface system of Java, as it is both easy to find faulty implementations, and impossible to differentiate implementations for which the properties are merely a recommendation from situations where not having a strict equivalence relation is problematic.

In the following paragraphs we shall cover a rather counter-intuitive aspect of equality comparisons in Rust.  Namely that the objects don't have to be of the same type.

To begin with, note that we have used an "associated" type =Self::Rhs= despite not having to implement it. This is in fact a generic argument, which means that there may be multiple =impl PartialEq<SomeType>= clauses.  If =Rhs= were an associated type, =PartialEq= could be defined only once per type.  And there are specific reasons why that would be advantageous, but in this particular case, we want to relax the type requirement for equality comparisons.

We would motivate this example by asking the question of whether or not in any circumstances in Rust, a reference should be compared to another reference strictly numerically.  Having, hopefully come to the conclusion that it is unnecessary[fn:27], we would then invite the reader to consider how many ways are there in Rust to represent a reference to another object.  As such it is often required to implement equivalence for objects behind an atomically counted shared reference, =Arc=.  Often if an object is behind a =Mutex= it is not possible to get direct access to any references similar to those types.

Thus to support comparisons for =MutexGuard= types, the vendor of the =Mutex= library must provide a blanket implementation.  To do so, then, =PartialEq= must work for different types.  And if these comparisons satisfy equivalence relations, =Eq= can also be implemented for them.

This is in stark contrast to the functional picture.  There are no types of boxes, separate from the types of values which are held in them.  As such, equivalence has no use for being generic.

**** =PartialOrd=

Partial ordering is yet another peculiar beast with surprising semantics.  As an indulgence let us consider how an implementation of =PartialOrd= would look for =Complex<T>=.

#+BEGIN_SRC rust
  impl<T: PartialOrd> PartialOrd for Complex<T> {
	  fn partial_cmp(&self, other: &Rhs) -> Option<Ordering> {
		  self.real.parial_cmp(other.real)
	  }
  }
#+END_SRC

Similarly to =PartialEq= there is a stronger requirement via the trait =Ord=.  Its implementation however, does entail extra work:

#+BEGIN_SRC rust
  impl<T: Ord> Ord for Complex<T> {
	  fn cmp(&self, &Rhs) -> Ordering {
		  self.real.cmp(other.real)
	  }
  }
#+END_SRC

What one might find fascinating is that there is nothing in Rust that would prevent these implementations from compiling.  The reason has to do with =Complex= numbers as we have modelled them here, and the mathematical aspects of true complex numbers.  The way we have defined ordering for =Complex= would result in fundamental problems if we were to define addition or multiplication.  Specifically, under this (projective) implementation =(0, 0).into().cmp((0,1).into())= results in equality.  The square of the imaginary unit is =-1=, while the square of =(0,0).into()= is itself.

#+BEGIN_aside
Now we might want to fix this problem by adding the imaginary comparison, and indeed, we would at least recover equality that way.  But there will still be issues with other aspects of total ordering; specifically when multiplication and addition are concerned.
#+END_aside

One must keep in mind that these implementations are what would be automatically generated for a very simple type, hence one must be exceedingly careful when applying mathematical thinking to traits, and viewing them as type-classes.  Hopefully we have demonstrated why that would be problematic to say the least.

*** The orphan rule
The Rust programming language diverges in a few key ways from the Haskell type class system.  While so far our demonstrations have been designed to differentiate Rust and Haskell, demonstrating Rust's impurity and un-fitness as far functional programming is concerned, the departures from the type class system are all reasonable, and in some ways may be considered an improvement.  In particular we would like to illustrate this on the previous example, of preventing an erroneous implementation =PartialOrd= for the type =Complex<T>=.

There are two ways to resolve the issue.  One, and perhaps the most complex is to consider giving up only on the total ordering =Ord= and instead provide a =PartialOrd= implementation.  To avoid issues when interacting with multiplication or addition, we only return =Some(ordering)= if the values have a zero imaginary part, and =None= in all other cases.  This will protect us from the contradictions, although it would make the implementation rather pointless.

The second option, one that the sensible majority opts for is to simply not provide an implementation.  This is quite effective when the type is included in a popular upstream library, one that does not have to integrate with anything else, and instead relies on downstream integration.  Case in point, =String= in the standard library does *not* implement =Copy=.  It is understood that if there were a way of making =String= a bit-copyable value, that the standard library maintainers would have done so.  If our =Complex<T>= were in the standard library and it did not implement =PartialOrd=, any reasonable downstream user would understand that =Complex<T>= is not amenable to partial ordering.

Unlike Haskell, if a trait is not implemented in either the library that implements the structure for which it is defined (generics are special), or the library in which the trait is defined, the trait is not implemented and cannot *be* implemented by any downstream user.

However, there is much room for ambiguity.  In fact it is impossible to tell in a downstream library if not implementing a specific trait is a design oversight, a temporary limitation that will later be lifted, or a statement akin to "this type should never implement this other trait".  Indeed the reason why a particular trait is not implemented can be practical: =serde= might be a too-large a library, or the trait =tracing::Value= might not be implemented, because it is far from the only logging library, and providing support for all logging libraries would either impractical or impossible.  Rust's approach is to externalise this problem: if the library is actively maintained, one can ask that to include a trait implementation if it is believed to be omitted in error.  If it is not possible to request inclusion, one can either vendor a modified version or look for an alternative.

Objectively speaking the orphan rule suits Rust.  Haskell has its own reasons to prefer an open world approach, namely the high resistance to publishing packages, the terseness of the language, and the assumption that there are fewer errant programmers willing to provide an instance of a type class for a type that doesn't.

*** Overlapping implementations

Both Rust and Haskell reject potentially overlapping implementations (instances) of traits (type classes), with some differences.  Specifically, Rust will complain about potentially overlapping implementations as soon as possible.  Haskell will defer until it is forced to disambiguate implementation.  Haskell has a language extension[fn:28] that loosens the class resolution so that even if two instances overlap, it is possible to choose a more specific instance.  Rust, has an extremely problematic implementation of specialisation, which in addition to its soundness problems forces both the library author and all downstream users of said library to use a =nightly= compiler, and explicitly enable the feature in the translation unit(s) where the specialisation is to occur.

In both languages it is highly recommended to avoid even potentially overlapping instances/implementations.

The reasons are quite similar, but the prevention mechanisms are different.  Haskell, living in an open world, cannot prevent potentially overlapping implementations even in principle. All it can do is ensure that if one module is not aware of another, the different implementations can work individually.  This has useful consequences when writing the program, but can potentially break if any of your downstream users would also like to adjust the implementation.

In Rust the prevention mechanism stops one from generating more than one blanket implementation for more than one trait:
#+BEGIN_SRC rust
  impl<T: Debug> Debug for Complex<T> {
	  //...
  }

  impl<T: Display> Display for Complex<T> {
	  //...
  }

  // but!
  impl<T: Debug> Display for Complex<T> {
	  // Error, potentially overlapping
  }
#+END_SRC
This sort of blanket implementation would be problematic in Haskell also, but only if one had been using a type which implements both =Debug= and =Display= is in scope.  For the respective subsets of complex numbers for types that only implement =Debug= only the debug subset is going to be used.

In Rust, even writing the above implementations is going to result in a compilation error.  In this case we know for sure that there are types which implement both, because to implement =std::error::Error=, requires the overlap.  It is not possible to write a "more specific implementation" in Rust, as it would be in Haskell.

#+BEGIN_SRC rust
  impl<T: Debug> Debug for Complex<T> {
	  //...
  }

  impl<T: Display> Display for Complex<T> {
	  //...
  }

  // but!
  impl<T: Debug> Display for Complex<T> {
	  // Error, potentially overlapping
  }

  impl<T: Debug + Display> Display for Complex<T> {
	  // Still error
  }
#+END_SRC
While it might seem that this kind of specification would automatically resolve all issues, alas it does not.

The corrolary of this in combination with the Orphan rule is that one would be implemeting a trait and providing a blanket implementation in far fewer cases than in /e.g./  Haskell.  But for reasons that shall become apparent later, it is also rarer to see individual implementations for custom traits, as one would expect in Haskell.

** Functions as arguments

Borrowing from functional languages, Rust supports passing functions as arguments to methods and functions.  The simplest example is the following method:

#+BEGIN_SRC rust

  impl<T> Option<T> {
	  pub fn map<U, F>(self, f: F) -> Option<U>
	  where
		  F: FnOnce(T) -> U,
	  {
		  match self {
			  Some(x) => Some(f(x)),
			  None => None,
		  }
	  }
  }
#+END_SRC
Note the number of generic parameters.  Firstly, the type stored inside the option is declared as part of the inherent implementation declaration.  Secondly, we are declaring two new types: =F= and =U=.  And we add an additional trait bound, but inside of a so-called =where= block, which allows for more elaborate trait bounds than /e.g./  declaring so in angle brackets.  Namely, we require that the function be applicable /once/ to the value of type =T= and return a type =U=.  This does not make each usage of =map= a mess, however, due to Rust cleverly deducing the return type from the function declaration, which is part of the reason why it was preferable to always provide function signatures.

Note that this implies that each invocation of =map= must be in-line; that is, that =map= may never cause a virtual call overheead, and thus there are no good reasons to *not* use map, other than an explicit =return= statement involving the enclosing function.  Unless the function passed to =map= is bound to the same exact name, no matter if the content of the function definition is identical, the functions are of *different types*.  For example, the function
#+BEGIN_SRC rust
  fn add1(thing: u64) -> u64 {
	  thing + 1
  }

  fn add1_again(thing: u64) -> u64 {
	  thing + 1
  }
#+END_SRC

are distinct types as far as the Rust type checker is concerned.

#+BEGIN_aside
Given that the type of a function is is not a higher-kinded type as in /e.g./ Haskell, but rather more akin to a /function pointer/, Rust allows for sound interactions between generics and trait objects and functions.
#+END_aside

Functions can be passed by name:
#+BEGIN_SRC rust
  let thing = Some(3_u64);
  let thing_plus_one = thing.map(add1);
  let thing_plus_two = thing.map(add1);
  let thing_plus_three = thing.map(add1_again);
#+END_SRC
If the function is associated to a trait, with the =Trait::function= syntax:
#+BEGIN_SRC rust
  let thing = Some(3_u32);
  let thing_plus_one = thing.map(Into::into).map(add1);
#+END_SRC
where =Into::into= first handles the conversion and then the argument is explicitly converted into a =u64=.

In more complex cases, such functions are usually defined in-place[fn:20]:
#+BEGIN_SRC rust
  let thing = Some(100_u64);
  let outcome = thing.map(|one_hundred| {
	  println!("got {one_hundred}");
	  return (one_hundred/100 as f64).into();
  });
#+END_SRC

*** =map= and monadic failure handling

With the exception of =panic=, all error handling mechanisms in Rust are explicit and involve a value being returned with the usual mechanisms.  While this is not too different from how it was possible, indeed, encouraged to handle errors in C (and to an extent C++), there are crucial differences in Rust's approach, namely, escaping the /tower of doom/.

In a C-like program.  It is common to see a pattern of nested =if= statements, whose sole purpose is to detect a rogue =falsy= value, namely =NULL=, but also error codes.  In most circumstances, the only sensible thing to do in that situation is to return the value, and exit the function, with rare exceptions in which it might also be necessary to terminate the program.

While it is certainly possible to do the same in Rust:
#+BEGIN_SRC rust
  let config_file = open(path);

  if config_file.is_some() {
	  let config_variable = config_file.clone().unwrap().variable;
	  let result_set_config_variable = some_subsystem.set_variable(config_variable);
	  if result_set_config_variable.is_ok() {
		  let some_other_config_variable = config_file.unwrap().some_other_variable;
		  if some_other_config_variable.is_some() {
			  let result_set_other_config_variale = some_subsystem.set_variable(some_other_config_variable.unwrap());
			  if result_set_other_config_variale.is_ok() {
				  //...
			  }
		  } else {
			  return None
		  }
	  } else {
		  println!("{:?}", result_set_config_variable);
		  return None;
	  }
  } else {
	  return None;
  }
#+END_SRC
This style is actively discouraged.

Instead it can be a chain of operations:

#+BEGIN_SRC rust
  open(path)
	  .map(|file| file.variable) // See [fn:20]
	  .map(|variable| some_subsystem.set_variable(variable))
	  .map_err(|err| {
		  println!("{:?}", err);
	  })
	  .ok()						// Convert to Option
#+END_SRC
which will implicitly decay to =None= whenever the opposite takes place.  The eagle-eyed reader will have found that this is not exactly equivalent to the previous example with the tower of doom[fn:21].

Because Rust is not a functional language, the typical patterns which would allow one to replicate the full logic of the tower of doom are much harder to express, and so the monadic style is supplemented by the =?= operator.

The statement
#+BEGIN_SRC rust
  let config_file = open(path)?;
#+END_SRC
is equivalent to
#+BEGIN_SRC rust
  let config_file = {
	  let maybe_config_file = open(path);
	  match maybe_config_file {
		  Some(file) => file,
		  None => return None,
	  }
  }
#+END_SRC
but much less verbose.  As such the above example with the tower of doom can be rewritten in an even simpler way:

#+BEGIN_SRC rust
  let config = open(path)?;
  some_subsystem.set_variable(config.variable)
	  .map_err(|err| println!("{err:?}"))
	  .ok()?;						// Note this conversion
  some_subsystem.set_variable(config.other_variable?)
	  .map_err(|err| println!("{err:?}"))
	  .ok()?;
#+END_SRC

Which is far more readable.  Note that we had to convert from an =Err= to =None= explicitly.  Rust does not implicitly destroy information and any lossy conversions must be done with the programmer's explicit consent.

We can apply the =?= operator inside functions that return either =Option= or =Result= until the =try= blocks are stabilised.

#+BEGIN_aside
New programmers often get confused about the scope within which the =?= operator works.  If it is called inside an anonymous function, the =?= returns from that function, and not the enclosing scope, which is why the destructuring control flow is sometimes preferred over monadic methods.
#+END_aside

To attain mastery, we propose practicing and memorising the following methods

| Option         | Result         | Use                                                                    |
|----------------+----------------+------------------------------------------------------------------------|
| =unwrap=         | =unwrap=         | Get enclosing success value, panic otherwise                           |
| =expect=         | =expect=         | Like =unwrap= but print custom message in addition to the error message  |
| =map=            | =map=            | Apply a transformation to the =Some/Ok=.                                 |
| =inspect=        | =inspect=        | Same as =map= except take reference and don't =move=                       |
| =map_or=         | =map_or=         | Same as =map=, but also replace =None/Err= with the provided default value |
| =map_or_else=    | =map_or_else=    | Same as =map_or= but lazy evaluate.                                      |
| =unwrap_or=      | =unwrap_or=      | Replace =None/Err= with the provided value                               |
| =unwrap_or_else= | =unwrap_or_else= | Like =unwrap_or= but lazy                                                |
| =transpose=      | =transpose=      | Convert =Option<Result>= to =Result<Option>= and back                    |
#+CAPTION: Monadic methods commont to both =Result= and =Option=.

| Option               | Use                                                                                           |
|----------------------+-----------------------------------------------------------------------------------------------|
| =ok_or=                | Convert to =Result=, by mapping =Some= and eagerly evaluating =None=                                |
| =ok_or_else=           | Same as =ok_or= except lazy                                                                     |
| =and_then= and =flatmap= | Apply =f= to the enclosed =Some= or else return =None=.  Used to collapse =Option<Option>= to =Option=. |
| =filter=               | Retain only values where =f= returns =true=.                                                      |
| =or=                   | Return either the original option if it =is_some= or replace =None= with the argument             |
| =or_else=              | Like =or= except lazy                                                                           |
#+CAPTION: Recommended monadic methods for =Option=.

| Result  | Use                                           |
|---------+-----------------------------------------------|
| =ok=      | Map =Ok= to =Some=, and lossy convert =Err= to =None= |
| =map_err= | Handle the error                              |
| =flatten= | Used to collapse =Result<Result>= to a =Result=   |
#+CAPTION: Recommended monadic methods for =Result=.

Mastery of these methods can go a long way to ensure readable code.


*** Destructuring, control flow

The less used, but no less useful are the methods specific to Rust.  We include them in the functional chapter, because we believe that these control flow constructs are useful when programming in the functional style, despite the fact that a lot of them would not make sense in a functional programming language such as Haskell or OCaml.

The first and simplest type of control flow is =if let=.  It acts like the boolean if, to the point of having a matching else, but also pattern matching on the interior of enumerations and binding a value only if the enumeration happens to be the right variant:
#+BEGIN_SRC rust
  fn print_if_some<T: Display>(maybe_value: Option<T>) -> Option<T> {
	  if let Some(value) = maybe_value {
		  println!("{}", value);
	  }
	  maybe_value
  }
#+END_SRC
These control flow constructs are smart enough to bind names to references if only a reference is needed for the body of the expression.
Similarly to the boolean =if=, if the expression evaluates to a non-trivial value, the =else= clause is mandatory.  In that case, the =if let/else= construct is equivalent to the wildcard pattern in =match=.

The =if= part can often be dropped, if the pattern is known as =refutable=, by which we mean that it requires more than two =match= clauses.  For example:
#+BEGIN_SRC rust
  let Ok(value) = u64::try_from(input) else {
	  panic!("Cannot convert {input:?} to `u64`");
  }
  value
#+END_SRC
This pattern is equivalent to =expect=, but that is not always the case, if for example, the pattern involves more than one value,  and isn't strictly a variant.  For example:

#+BEGIN_SRC rust
  let (Some(Some(value)), None) = (maybe_maybe, definitely_none) else {
	  panic!("Faulty logic, above code should be checked for correctness");
  }
  value
#+END_SRC

If the pattern is not =refutable=, that is, it can be matched with /one clause/ the =else= part can be dropped.

One particularly good application for =while let= is in loops over iterators.  If for some reason the monadic iterator methods cannot be used, /e.g./ =map=, =reduce= /etc./; =while let= can greatly ease the usage of =Iter::next= to continue iteration.

#+BEGIN_SRC rust
  while let Some(value) = some_iterator.next() {
	  return_iterator.push(value);
  }
#+END_SRC
This loop acts almost identically to the original =while=.  It has some advantages also in situations in which the appropriate boolean trait is not implemented for a particular type, but a condition is needed:

#+BEGIN_SRC rust
  while let Complex{ real, imaginary } if real > 0 && imaginary > 0 = cmplxs[i] {
	  println!("Point is in first quadrant");
	  i+=1;
  }
#+END_SRC
In this example, we know that ordering cannot be defined for the field of complex numbers.  We do however, care about the individual values, for which total ordering is defined, and after binding them, we simply add a guard statement which has the required predicate.

Another important location where irrefutable (patterns with one possible structure) are used is in destructuring a value.  We touched upon it with respect to =let= statements, but Rust also allows one to destructure irrefutable patterns in function arguments.  This is often useful for getting rid of =self= in method implementations:

#+BEGIN_SRC rust
  fn norm(Complex{ real, imaginary}: &self) -> {
	  return real*real + imaginary*imaginary
  }
#+END_SRC
Needless to say this pattern is rare to see, because it is often overshadowed by =self= in terms of clarity, and the dot-syntax in terms of maintainability.  Unless the value has a short name with values bound by name, it is often shorter to repeat =self= or to bind those values with =let= and the dot syntax.

*** The =match= statement

Now we come to the most powerful of Rust's pattern matching facilities.
=match= is often misused in cases where an =if let= or =?= should have been used.  One of its key advantages is that =match= can act on nested patterns.  One particular example is
#+BEGIN_SRC rust
  pub fn env_or_fail(candidates: Vec<&'static str>) -> Result<Option<String>, Error> {
		  let mut found = None;
		  for candidate in candidates {
			  match (&found, std::env::var(candidate)) {
				  (_, Err(std::env::VarError::NotPresent)) => continue,
				  (_, Err(std::env::VarError::NotUnicode(_))) => {
					  eprintln!(
						  "The environment variable value for {candidate}, was not valid unicode"
					  );
				  }
				  (None, Ok(value)) => {
					  found = Some((candidate, value));
				  }
				  (Some((previous_key, previous)), Ok(value)) if *previous == value => {
					  eprintln!("Redundant specification via environment variable {candidate}. Previously set via {previous_key}");
				  }
				  (Some((previous_key, previous)), Ok(value)) => {
					  eprintln!("Inconsistent specification via environment variable {candidate}. Expected {previous} found {value}");
					  eprintln!("This may be a configuration error, aborting");
					  return Err(format!("The environment variable was set twice, {previous_key} to {previous} and {candidate} to {value}"))
				  }
			  }
		  }
		  Ok(found.map(|(_, value)| value))
  }
#+END_SRC
This function when given a collection (=Vec=) of potential names for each environment variable does the following: it checks if the variable is unset, this is normal.  If the variable is set to invalid unicode, we mainly want to notify the user that it was, and continue searching.  Invalid unicode in one of those variables is not a problem, if another candidate string contains a known value.  Before this point, what is contained in =found= does not concern us, so we ignore it.

After we have identified a valid string, the situation is different: we remember the key with which the value was set, and assign the value.  After this point, the pattern with =None= is never going to recur; but the pattern with invalid unicode, no variable and a another variable set can still occur.

Under ordinary circumstances it'd be enough to terminate the function as soon as the first match is found, but we want to notify the user if they have accidentally set the value twice via two aliases.  If the two values are identical, it's fine, though the user should be aware of this.  If the values are different, then there's very likely some overriding which didn't go according to plan...

In other languages this would be difficult to express, either because they don't have the pattern matching facilities to enumerate the different possible scenarios as cleanly as we have.  Or because they are very stringent on mutation, and overriding the value =found= would be far more verbose.  As such, Rust has its own style that is unlike any other language.

*** Error handling, panics

In Rust, there is a great deal of decision making that is about delegating responsibility.  The =?= operator is a clean way of delegating failure in the current scope, to the enclosing scope.  With Options, that happens trivially, only the type =T= is important.  With =Result= the =?= operator also handles conversions, if the error type in the enclosing scope can be constructed from the current error.  This is often the case if the current error is a variant in the enclosing scope's error =enum=.

Specifically it is commmon to see a pattern in which a library defines an overall =enum= for all conceivable errors as variants.  Sometimes, if there are too many variants, the patterns are split into trees.  Within those trees each leaf is its own type, asny branch is an =enum= that contains a =From<LeafType>= implementation for each such leaf.  All of these additionally implement =std::error::Error= which is the standard library error trait, which additionally requires the Error types to implement =core::fmt::Debug= and =core::fmt::Display=.  As a consequence, all functions that return =Result= often return the same error type, thus becoming true monads.  The leaf errors can be converted implicitly by =?=.

This style suits libraries best, some better than others.  No information is lost, an accurate picture of a cascade of failures can always be recovered at the top level.  Dependent libraries must obviously wrap their dependencies' error =enum=-s, as if they were leaf types.  However this pattern often results in poor interoperability with user-facing code, and works poorly in libraries such as =serde= where errors must be wrapped in a concrete library-provided type, which invariably destroys information.

This pattern also leaves no room for reframing the context and results in poor signal-to-noise ratios.  Consider this situation.  A single service may need multiple socket connections: particularly if said service is a message relayer.  Failure to connect to each and every one of those services is distinct, and often the only possible error to be returned.  As such, it is often prudent to consider the following construction:
#+BEGIN_SRC rust
  pub enum Error {
	  PrimarySource(SocketConnectError),
	  PrimaryDestination(SocketConnectError),
	  SecondarySource(SocketConnectError),
	  SecondaryDestination(SocketConnectError),
	  Database(Either<SocketConnectError, DatabaseError>),
	  // .. other types
  }

  pub enum SocketConnectError {
	  PortInUse{
		  port_number: u16,
	  },
	  Permissions {
		  port_number: u16,
		  user: UserAccount,
	  },
	  NonLocalHost {
		  host: String,
		  port_number: u16
	  },
	  // etc.
  }
#+END_SRC

The top-level error enumerates all conditions which are errors.  For a specific type of failure, we create a separate enumeration.  To reframe an error, we can specify an implementation of =TryFrom<std::io::Error>= which maps the underlying, rather problematic error type, to a regular "nice" local error type.  The crucial aspect is that this =SocketConnectError= can assume things about the context that the general implementation in the standard library cannot.

Specifically, as a program developer we know that the inability to bind to a specific port can mean that either something else is using it, in which case we can use the standard Unix toolkit to find that program and tell the user to kill it.  We can reframe the typical error message =OS Error 11: Connection refused= to something that is far less confusing: =failed to bind to port 8080, because that port is already in use=.  We can do so by implementing =core::fmt::Display= for =SocketConnectError=.  Additionally we can tell which part caused the error, because the error can be =match=-ed on, and additional context, /e.g./  where that string was set can be added.

In practice Rust permits extremely well-designed applications, even following this simple tree-like pattern.

Unfortunately what one most commonly sees is a top-level enumeration that basically categorises the errors by type; this certainly makes the invoking code simpler: starting from
#+BEGIN_SRC rust
  pub fn init(self) -> Result<Self, Error> {
	  libnetworking::connect_host(self.primary_source)
		  .map_err(TryInto::try_into)?
		  .map_err(Error::PrimarySource)?;
	  libnetworking::connect_host(self.secondary_source)
		  .map_err(TryInto::try_into)?
		  .map_err(Error::SecondarySource)?;
	  libnetworking::connect_host(self.primary_destination)
		  .map_err(TryInto::try_into)?
		  .map_err(Error::PrimaryDestination)?;
	  libnetworking::connect_host(self.secondary_destination)
		  .map_err(TryInto::try_into)?
		  .map_err(Error::SecondaryDestination)?;
  }
#+END_SRC

#+BEGIN_SRC rust
  pub enum Error {
	  Io(std::io::Error)
  }

  impl From<std::io::Error> for Error {
	  //...
  }

  pub fn init(self) -> Result<Self, Error> {
	  libnetworking::connect_host(self.primary_source)?;
	  libnetworking::connect_host(self.secondary_source)?;
	  libnetworking::connect_host(self.primary_destination)?;
	  libnetworking::connect_host(self.primary_source)?;
  }
#+END_SRC
Sure the second code is far shorter, but if handed off to someone who is not a Rust programmer, it is quite possible for them to think that something is wrong with their operating system, because the error message in the poorly considered =std::io::Error= doesn't clarify that =Os Error= means an /Error/ returned *by* the operating system, not *of* the operating system.  The information about which of the socket speicifications was wrong causing the error, is also lost.

As a middle ground, it is often said that the =anyhow= or =eyre= libraries can compensate for the lack of context:
#+BEGIN_SRC rust
  use eyre::WrapErr;				// Import trait so method is usable

  pub fn init(self) -> eyre::Result<Self> {
	  libnetworking::connect_host(self.primary_source).wrap_err()
		  .wrap_err("Failed to connect to primary source")?;
	  libnetworking::connect_host(self.secondary_source)
		  .wrap_err("Failed to connect to secondary source")?;
	  libnetworking::connect_host(self.primary_destination)
		  .wrap_err("Failed to connect to primary destination")?;
	  libnetworking::connect_host(self.primary_source)?
		  .wrap_err("Did you notice that the shorter version also had the primary source twice?")
		  .wrap_err("Failed to connect to primary source again")
  }
#+END_SRC

However, these errors can no longer be handled in any way other than printing.  More importantly, the description of *what* went wrong is inlined into the function, meaning that while each =eyre::Result= is potentially wrapping different errors, the user is not notified of situations in which they can reasonably handle those.  Simply returning an =eyre::Result= can mask potentially different error conditions and the programmer knows nothing other than certain operations are fallible.

This is a problematic situation.  And not entirely within the best practices of functional programming.  Still, even highly regarded functional programming langauges have less than ideal error handling methods, with exceptions being particularly problematic in functional programming specificially.

** Function taxonomy

Rust is a rather peculiar language as regards functions.  To any functional programmer, calling any of the aforementioned entities functions is an abhorrent misnomer.  Most functions are not pure.  In fact, despite functions not allowing mutation as easily as most imperative languages, for anything but the =Copy= types, every function has an inherent side effect of invalidating the object in the enclosing scope.  This is especially problematic in anonymous functions (or more accurately procedures) as they can capture enclosing objects both by borrow and by =move=[fn:22].

This results in the programmer necessarily having to engage with function taxonomy.  If not to know how to accept a function, but to be able to decode the error message any programmer must know the difference between =Fn=, =FnOnce= and =FnMut=.

#+BEGIN_aside
This is in stark contrast with functional languages, such as Haskell.  One might be asking why this was included in the functional description of Rust and the answer is two-fold.

For one, assuming that Rust is a functional language is a common misconception.  We want to explain how Rust is not a functional programming language.

The second and perhaps the more important reason is that while Rust is most assuredly not an FP language, it has intentionally replicated some of the patterns common to the functional style.

As a consequence, a functional programmer can feel more comfortable in Rust than in a traditional imperative or OOP language, because some of the higher-level design patterns are replicated.  To ease that transition we must cover the important differences that a typical functional programmer might see as quaint, or problematic.

As such we must cover the various ways in which functions are categorised in Rust.
#+END_aside

*** Repeat invocations

Paradoxically the most common type of "function" is =FnOnce=.  It is automatically implemented for functions that accept one argument of any of the non-copy types by value.

One might wonder why a function like that is inherently callable once only: indeed, we could call such a function in a loop if we simply =Clone= a value into the function invocation during each iteration.  Unfortunately, this is one of the many situations in which the inherent Von-Neumann-ness Rust rears its ugly head.  This is because the binding of a name to a function parameter is something that is ambiguous in this particular context, which it wouldn't be if one were in the Church formalism.  A value is a value in lambda calculus.  A Rust object is something that has a lifetime that must be respected.

*** Mutability

Suppose we got rid of accepting values by move, and only passed objects by borrow.  In any imperative programming language, whether or not we mutate any of the input parameters is irrelevant.  In a functional programming language, this fact is carried through via either the =Ref= or =Io= monads.  Rust is more principled than C: values can either be shared or mutable, so we need to differentiate functions that mutate their values.  But because we don't have the typical linear type system, as such we cannot extract the mutability into the output(s) of the function.  So the function itself is decorated as =FnMut=.

One may then ask a very reasonable question, is =FnMut= also =FnOnce=.  Unlike most situations the answer to this question is simple.  A mutating function can be called both repeatedly, but also once.  So =FnOnce= is a strict subset, or subtype of =FnMut=, and because these are traits, not types, this form of inheritance is perfectly reasonable within the Rust framework.

*** Purity

Most if not all functions in Rust are fundamentally impure.  A small subset of functions, however, is pure.  There is an overlap with the =Fn= trait, but that overlap is far smaller than one might assume, and is not enforced at the type level.

Specifically, we have already seen situations in which a value can change behind a shared borrow via interior mutability.  Because there are not monads inherent in Rust, it is impossible to differentiate functions which truly do not mutate the state that they borrow, from functions that do.

The only way a Rust function can be guaranteed to be pure based on its signature, is if it only accepts =Copy= values by move.  Even then, this is a tenuous purity given that some foolish programmers may implement =Copy= for types which contain non-=Copy= types.  As such, one must be careful when considering whether a function that is =Fn= is truly pure and truly a function.

***  Trait methods

It is now important to consider how and why associated functions are called associated functions.  For all intents and purposes, bar encapsulation, an implementation is identical to a function that accepts a parameter of type =Self= in the first position.

As such a mutator function is =FnMut=, a trait implementation such as =Into::into= is =FnOnce= and a getter function is =Fn=[fn:23].

*** Asynchronous functions
**** Interlude =Send= and =Sync=

Now we come to the most controversial part of the topic of functions.

Rust prevents inherently problematic threaded code from compiling.  However it did not initially anticipate the most common type of concurrent programming would not be threaded, but in fact asynchronous.  The reason for that change was that initially it was assumed that Rust's attempt at replicating functional patterns would lend it to sufficiently simple compiler-based multi-threading.

Indeed, some of that is still present in modern Rust, namely the wonderful =rayon= library.  It was later discovered that a more efficient approach would be to allow Rust to support =Future=-based co-operative multi threading.  As it was a relatively late addition, some aspects of =async= are to this day poorly integrated with the rest of the language.  As Rust does not support higher kinded types, it is not possible to rely on the solution of functional programming languages to represent =Future=-s.  And so the work done for Rust is pioneered, so it'd be worthwhile discussing how the mechanism works and what its limitations are.

As we have stated previously, Rust's type system does not have support for general purpose monads, otherwise, this point would be moot.  Additionally Rust must cater to the fact that a lot of its types have complex inner state that must be properly synchronised.  The borrow checker helps considerably in that regard, but using an =Rc= instead of =Arc= and =RefCell= instead of =Mutex= must be accounted for.

As such, there are two more traits: =Send= and =Sync=.  To understand what they mean, we need to dive deep into the Von-Neumann multithreading model.

Unlike the Lambda calculus, in principle every execution thread and every asynchronous runtime worker can have access to the entirety of the program's shared memory.  Given the pass-by-move semantics, it is possible to define sending an object from the areas of memory that belong to one thread to another area of memory.  If an object remains valid if passed by move from one thread to another, it is considered =Send=.

If the object can also be shared without causing an inconsistency, it is considered synchronised, /i.e./  =Sync=.  One can immediately see that if the object of type =T= is =Sync= then it is shared by =&T=, and therefore =&T= must be =Send=.

Now let's look at why =Rc= and =RefCell= cannot implement these traits.  We start by noting that incrementing the same number from two threads is an operation that may result in either one of the increments being lost.  As such, the reference count integer no longer represents the number of actual users of the =Rc=, and it is possible that the =Rc= is freed long before the last user of the value has been =Drop::drop=-ed.  A similar situation occurs with =RefCell=.

Given that moving a type is a recursive move of all the contained data, any type that contains either an =Rc=, =RefCell= or =UnsafeCell= is also neither =Send= nor =Sync=.

#+BEGIN_aside
Technically, a raw pointer should also be marked as neither =Send= nor =Sync=, but because raw pointer operations involving dereferencing are unsafe anyway, it was decided to treat pointers as plain =Copy= values.
#+END_aside

So why is an =Arc= thread safe?  Consider that we had a very simple implementation using an =AtomicU64=.  All reads are thread safe, and in order to write to an atomic integer, we must first have read from it, so if a concurrent modification did occur, we would at least know that it did, and know what to do.  A lot of this logic is hidden, so we don't need to worry about using an =Arc= in a concurrent[fn:24] context.

What this amounts to is that a piece of data that cannot be safely sent between threads is safe to be shared when wrapped with =Arc=.  Similarly, state that isn't =Sync= can be made =Sync= by wrapping it in a[fn:25] =Mutex=.

Having covered these two traits we can now talk about what exactly is an =async= function.  In modern Rust these are implemented outside the compiler and there are no special exceptions made for =async=, as such a function with the definition

#+BEGIN_SRC rust
  async fn func(a: Complex) -> Box<Complex> {
	  // ...
  }
#+END_SRC

is merely syntactic sugar for a return position opaque generic: =impl Future<Output=Complex>=.   This necessitates another interlude.
*** TODO Futures and runtimes

So what exactly is a =Future=.  Well it's a trait, that is implemented by various types and represents a computation[fn:26] that is not running in the current thread.  Dropping the =Future= signals that the computation is not needed, and that the thread doing it can be used for other purposes.

It has one method =poll= which is called when the computation is to be resumed, and when the computation is complete returns the result of it.  It also has one associated type: =Output=, which is used for type checking only.

The exact elaborate dance that must take place to give programmers the illusion of simplicity is beyond the scope of this book.  Suffice it to say, most areas pertinent to asynchronous computation are still under construction.

The eagle eyed reader will have at this point asked, how does the computation take place in =async=, given that =Future= only addresses the question of communicating the computation's result back to the call-site.  Well, Rust unlike Go, decided not to provide an asynchronous runtime by default or in the standard library, but instead to rely on the package ecosystem to provide one.  Indeed, while =tokio= is considered the best runtime as of writing, it is far from the only such runtime.

But it is the run-time library that is responsible for spawning lightweight threads.  It can leverage POSIX threads and can perform concurrent operations with a single operating system thread.  This allows one to spawn small execution threads for tasks which are bounded by input/output bottlenecks, rather than computational complexity, even though technically =tokio= could handle those too.

So let us illustrate this on a simple example:
*** The problem of coloured functions
** TODO Recursion

Rust supports recursion to some extent.  It must be noted that defintions of some concepts, namely addition for numbers, or =Default::default= almost always harbour unwanted recursion, which has famously necessitated the implementation of =Box= as a compiler-provided type, rather than as a standard library type that could be implemented in another library.

Rust [[https://github.com/rust-lang/rfcs/pull/81][doesn't guarantee]] tail call optimisation, even in places where one would expect it to be active.  Given the complexity of the Rust compiler, the intermediate representation and the machinery in LLVM, it is rather difficult to say if one can use the functional-style tail-call optimisation at all, without risking stack overflow.

#+BEGIN_aside
Rust does have areas where recursion is quite prominent if not required.  Macros in Rust have many of the features traditionally associated to functions in functional programming languages, but due to the fact they serve a different purpose, and are honed to solve a different problem, we must cover them in later chapters, focusing on function recursion for now.
#+END_aside

It might be wise to cover the implementations of certain traits.  Consider how one would implement the =Default= trait.

Our structure recursively calls the default constructors for its constituent members.  This is often a rule, with very few exceptions.  Yet one cannot declare that as a short-hand.

#+BEGIN_SRC rust
  pub struct Compound {
	  a: A,
	  b: B,
	  c: C,
	  d: D
  }
#+END_SRC
** TODO =const=


* Rust as a unique language

Rust is unique.  Of all the paradigms listed, Rust only fits OOP well, and even then, it is the one paradigm that it had deliberately distanced itself from, by disallowing inheritance.

And while every feature listed so far had been inspired by families of languages, Rust has a few features which are specific to it, which may be regarded as inspired by specific languages which are not protypical examples of any paradigm mentioned so far.
** Macros

Many languages have macros.  Rust is unique in the roles that macros fill because of their interactions with the trait and type systems.  Some limitations, for example the fact that Rust macros can't access type information unless explicitly annotated, are unique to Rust.  Some applications, for example =derive= macros would have been useful in languages with a type class system.   This all results in a unique flavour of programming that anyone just starting out with Rust should get accustomed to.

So let us begin.

***  Macro applications

Macros have a much wider range of applications in Rust.  Typically they are used in situations in which a domain-speicific language can simply express relationships that are clumsy using Rust's ordinary syntax.  In fact, all of the macros that we've seen so far and most of the macros that we will see in the following chapters typically do just that.

It is, however, possible to use macros to execute arbitrary compile-time logic.  In principle, type checking, executing arbitrary code and having arbitrary side effects is something that macros can do, but it is considered a bad practice to do so, not to mention relatively inefficient.  However, by their very nature procedural macros are essentially a way of calling functions that accept a token stream and producing another token stream in return.  One may call external programs within procedural macros if they need to.

It is important to distinguish macros by invocation.  Specifically, what they are intended to accept as input.

The first and easiest to understand are function-like macros, which acccept all code that has the same token structure as Rust.  The use of these macros is reserved for cases wherein the syntax is indeed radically different.  Case in point, =print= and =println= are macros which do not follow typical Rust conventions for syntax.  They do not accept good-old-fashioned Rust except in the position of arguments, even then with limitations.  The entire point of =print= is to translate the non-Rust formatting mini-language into a more verbose language.

Function-like macros can accept either parentheses, square brackets or curly braces, and while there very few rules about which syntax is preferred in which situations, it is commonly accepted for macros that accept extended blocks of text to use curly braces, square brackets to be used for macros that accept a list-like object, and parentheses in the remaining situations:
#+BEGIN_SRC rust
  dsl::block! {
	  registry abc;

	  abc.push $1;

	  abc.push $2;

	  abc ++ $3
  }
#+END_SRC
In this case, the curly braces are used because the rest of Rust also uses curly braces to delimit block expressions.

#+BEGIN_SRC rust
  let list_ascending = vec![1_u64, 2, 3, 4, 5, 6, 7];
  let mut list_of_ones: Vec<u64> = vec![1; 7];
  list_of_ones.push(2);
#+END_SRC
The square brackets are used to give the user a familiar syntax.  A list in square brackets is like an array definition, while a semicolon usually means to fill the vector with the given element.

#+BEGIN_SRC rust
let countries = sqlx::query_as!(Country,
		"
SELECT country, COUNT(*) as count
FROM users
GROUP BY country
WHERE organization = ?
		",
		organization
	)
	.fetch_all(&pool) // -> Vec<Country>
	.await?;
#+END_SRC
The round parentheses are used to signal that in most situations, the code inside would have been interpreted by a function.  Because Rust's =const= is not as powerful as its procedural macros, and/or for some reason the computation must be carried out at compile time, the macro system can be used.

Next there are *attribute-like* macros, which are mainly used for parsing what is ostensibly valid Rust syntax, /e.g./  a block or a function, but to change it in some way.  For example, the =tracing= library defines the =instrument= macro, which creates a span that decorates a function, the return type and signature don't change, but the information inside the signature is used to annotate the span with the precise values of the arguments for each function.

#+BEGIN_SRC rust
  #[tracing::instrument]
  fn complex_function_that_may_misbehave(
	  argument1: Arg1,
	  argument2: Arg2,
	  argument3: Arg3,
  ) -> Result<Thing, Error> {
	  function_that_may_log_error(argument1, argument2)?;
	  function_that_has_event_loop_and_no_access_to_args()?;
	  // Some work
  }
#+END_SRC

In this scenario, the attribute macro can decorate and modify the function.  It may be bound under a different name, it may generate more than one function, it may change the behaviour of the function but by the principle of least surprise, the code inside the annotated function *must* be executed as valid Rust.

Attribute-like invocations aren't always macros, for example =#[allow(clippy::unwrap_used)]= is a built-in to signal to =clippy= that /that/ lint: =unwrap_used= is OK in the following statements.

Attributes can annotate the following statements, or the enclosing scope: =#![allow(clippy::unwrap_used)]= applies to the module that it's in, not the module or function that follows.

It is often the case that if a special annotation is needed inside another macro, but one wants to preserve the natural Rust syntax, the attribute-like objects can be used to decorate such items, without necessarily corresponding to a macro.

It'd be more appropriate to state that attribute-like macros can be used to implement special functionality by plugging into the attribute syntax that the Rust compiler already knows how to handle.

Last but not least are derive macros.  These are very strict in what they must do: they always accept a valid Rust structure, that may be annotated with attributes.  They, as a rule, do not define custom syntax and never annotate anything else.

The most common example is the following:
#+BEGIN_SRC rust
  use clap::Parser;

  #[derive(Debug, Clone, Parser, serde::Deserialize, serde::Serialize)]
  #[command(author = "me", version, about, long_about = LONG_ABOUT)]
  pub struct Args {
	  /// Where to bind the web server.
	  #[serde(rename = "from")]
	  host: Option<SocketAddr>,

	  /// Where to post to
	  #[arg(long, short)]
	  #[serde(rename = "to")]
	  target: String
  }
#+END_SRC
In this example we are producing default implementations for traits whose name is conventionally given in the =#[derive]= annotation.  The standard library (or rather the compiler) provide ways of deriving both =Clone= and =Debug=.  While there are technically no procedural macros to which they correspond, they could be (and often are) derived in a procedural macro.

Next we are providing three library implemented derive traits: =Parser= that was imported using the standard =use clap::Parser= and fully qualified =serde::Deserialize= and =serde::Serialize=.

Both the =clap= and =serde= macros interpret the entirety of the body of the structure.  Clap uses the documentation string to generate a help message for the program's =--help= key.  Serde and Clap use the fact that the object is annotated with an =Option= to treat omitting the value as normal.  If we defined our own =Maybe= type which was identical to =Option= in every way, the behaviour would be different and =host= would be a required argument.

Next, we provide optional information specifically to =serde=.  The authors of the macro decided to make any annotation of the style =serde(<expr>)= mean directives to be parsed by =serde=.  In this case the directive is to rename the option to =from= in the supported formats.  =Clap= follows a different convetion: it parses every =arg= annotation.  Additionally, clap applies an overall =command= annotation to the structure, which =serde= can see, but ignores.  The code inside of the annotations is a mini-language in which omission of certain terms can have significance[fn:29].

Derive macros are usually provided if there is a clear default that can be gleaned directly from the structure, and supplemented by external information.   Because procedural macros are procedures that accept tokenised code and return tokenised Rust code, and =derive= macros annotate the structure and not any other code fragment.  The reason is that they must see the structure's fields.  This limiatation shall become important later.

*** Macros by type

Rust supports defining macros in two ways[fn:30].  The commonly accepted opinion is that it is easier to write declarative macros.  And while that statement may be true subjectively, declarative macros are more limited in what they can do, much harder to read, and often result in unoptimised recursion.  By contrast, well-written procedural macros differ only in the amount of boilerplate, more powerful and much easier to unit test.  Crucially, it is easier to write optimised code with procedural macros.

For this reason this book will go against the common "wisdom" and cover procedural macros first.

The Rust infrastructure favours procedural macros compiled from Rust source code.  This is not a hard requirement, as much as a convention.

*** Procedural macros in-depth

It is a common misconception to think that procedural macros are more difficult to write.  This perception is due to a combination of the following:
1) The more involved attribute-like and derive macros can only be written using procedural macros.
2) Rust inherently only provides access to the tokenizer and not the parser, meaning that one has to use external libraries to parse said structures.
3) The libraries typically used for procedural macro creation: =syn= and =quote=, are rather difficult to work with.

Because of that, it is quite likely that the procedural macro that you are likely to be writing, is likely not going to be a good experience.  But in all fairness, the barrier of entry to procedural macros is rather low.

One only needs to create a new crate, with the extra option of =proc-macro = true= set in its =Cargo.toml=, and write a single function annotated with /e.g./  =proc_macro_derive(NameOfTrait)= and be off to the races.

A hello world program looks relatively simple:
#+BEGIN_SRC rust
  #[proc_macro]
  fn hello_world(input: TokenStreaem) -> TokenStream {
	  "fn hello_world() -> { println!(\"Hello world\"); }".into()
  }
#+END_SRC

#+BEGIN_aside
The appalling quality of =syn=  and =quote= is a matter of perspective and by no means an evaluation of the skills of its authors.

With that said, there are compounding reasons why these crates are not given as much attention and of the wrong kind.

Firstly, the typical users of procedural macros are self-selected experts in the language.  Certainly people with an above average mastery of the rest of the language.  They after all need not just generate correct code, but also to write a program that will always generate the correct code.  People of this kind are less likely to engage in poelmics, or to complain.  So while some design choices are questionable, once the user of =syn= and =quote= found out how to circumvent a particular problem, they are unlikely to encounter that same issue and consequently be annoyed enough to report it.

Secondly, the procedural macros are typically responsible for a non-parallelisable segment of compilation that blocks compilation of every crate that depends on them.  Furthermore, these procedural macro crates are both compiled and executed.  This leads to a compound pressure to reduce the complexity of both =syn= and =quote= meaning that they are heavily feature-gated, but also that if a piece of code /could/ be omitted, it usually /is/.

Thirdly and perhaps most importantly, procedural macros are under considerable development: the Rust team is inching towards relaxing a few of the restrictions imposed on procedural macros, which may potentially make both =syn=, =quote= and *any* similar crate redundant eventually.  There is a lot more incentive to make the built-ins work better, than it is to try and fix a community library.  
#+END_aside

* Action items
** TODO Mention pointers and unsafe
** TODO Mention array index notation in the /procedural/ chapter
** TODO Opaque generics

* Appendix
** =async_trait= and dynamic dispatch

Due to complications of the Rust type system, the exact syntactic sugar when applied to a trait implementation does not work.   In fact, while in most circumstances the functions can be regarded as generic, to this day, the implementation of =async= in trait associated functions must desugar to a different construct to act as one would expect them to.  Namely, they desugar to
#+BEGIN_SRC rust
  Box<Pin<Future + Send + Sync + 'lifetime>
#+END_SRC
Which utilises *dynamic dispatch*, even though it should be noted that the LLVM compiler may still inline the virtual calls.  Rust version =1.75= roughly addressed the impossibility of using the previous definition, at all, but it still does not permit constructing trait objects out of traits with =async= functions.

** Worked example: custom traits

We must now consider how one can define traits, on a practical example.  The above =Complex<T>= structure definition allows one to construct types that are not sensible: for example =Complex<bool>= or =Complex<char>=.  We would like to differentiate the primitive types that represent numbers from other general primitive types.

#+BEGIN_SRC rust
  pub trait Numerical {}
#+END_SRC
Our first stop is what's called a /marker trait/.  The implementation of this trait is low-effort and can theoretically be done for all possible types.  For example,
#+BEGIN_SRC rust
  impl Numerical for u64 {}
#+END_SRC
/marks/ =u64= as =Numerical=.

We can assume that given that we are not going to have such statements for =char= and =bool= that amending the structure definition of =Complex<T>= to
#+BEGIN_SRC rust
  pub struct Complex<T: Numerical> {
	  real: T,
	  imaginary: T
  }
#+END_SRC
would be enough.  But this will result in =Complex<T>= being rather awkward to use.  At present it can neither be cloned nor printed, nor indeed compared for equality.  Arithmetic cannot be defined over complex numbers, because having a generic function of the form
#+BEGIN_SRC rust
  impl<T: Numerical> Complex<T> {
	  fn norm(&self) -> T {
		  self.real * self.real + self.imaginary * self.imaginary
	  }
  }
#+END_SRC
would not compile.

So at this point we must consider which properties of =T= are intrinsic to =Complex<T>= being useful as a complex number, and which are helpful, but not required.

Firstly, consider how a complex number is defined in abstract mathematical terms and how that definition is different from /e.g./  a two dimensional vector.




* Footnotes
[fn:30] Arguably one, because the mechanism by which declarative macros are written can be perfectly replicated by means of procedural macros.

[fn:29] As can whitespace in general, although practice dictates to avoid that.

[fn:28] To be fair, Haskell's implementation is deprecated as of  GHC 7.

[fn:27] To understand why, consider that Rust does indeed have pointers.  However, comparing pointers for equality is different to comparing references for equality given that in Rust specifically values are either mutable or shared.
[fn:26] A =Promise= by contrast represents the value that may be extracted from the computation in the future.

[fn:25] While the standard library =Arc= is considered good-enough in all but the most esoteric cases, there are many providers of a =Mutex= type, all of which have different trade-offs.  Including the standard library that provides both a =Mutex=, and an =RwLock=.

[fn:24] It should be noted that the complexity of an atomic reference increment does impact code that doesn't need multi-threading.

[fn:23] Perversely, a getter is only sensible if the value can change past creation, which is why functional languages very rarely if ever have them.

[fn:22] If requested with the =move= keyword.

[fn:21] and also that anonymous functions are permitted to capture objects from the enclosing scope.  This shall become important in later chapters.
[fn:20] This is particularly useful, because the point-free notation in Rust doesn't allow access to specific fields.

[fn:19]  Converting pointers gotten from FFI to =Option<Box>= is a different matter entirely, as it can lead to double free, or use-after-free, if e.g.  that pointer is managed by the external library.

[fn:18] One remarkable application of monads in Rust would have been =unsafe=.  Unfortunately it would have introduced a somewhat impractical delineation between =unsafe=-in-principle code, and code that uses purely safe Rust.

[fn:17] The type itself is not special, but its structure is handled in a special way by the Rust compiler.

[fn:16] While writing code via generics guarantees that it will be monomorphically dispatched, trait object code can also be de-virtualised by LLVM.

[fn:15] The slice is an example of a fat pointer, in that =&[u8]= is both a reference to the first element of the array, and the length of said array.

[fn:14] The reason is simple.  If your function accepts a =&Parrot= you should invoke =&zoo.parrot=, rather than =zoo.as_ref()=.

[fn:13] Although historically dynamic linkage was preferred.

[fn:12] This is most useful in using =enums= which we shall talk about later.

[fn:11] Which we have not covered in this section, as they do not work as strings in procedural languages.

[fn:10] As in =super::super= is not the parent of the parent.

[fn:9] That module is almost always a file =lib.rs= in the =src/= subdirectory of the project.

[fn:8] Out-parameters, are generally accepted, but not common.

[fn:7] A point that is somewhat frustrating to new users is that taking a mutable borrow invalidates any immutable borrows.

[fn:6] We shall see later, why the mutability nomenclature is somewhat misleading.

[fn:5] This situation is a newbie mistake when using the Rust =getopt= library.

[fn:4] The parallel to =return= is also in that a =break= without a value is assumed to "return" =()=.

[fn:3] The collection over which iteration takes place.

[fn:2] A full list is [[https://doc.rust-lang.org/reference/expressions.html][available here]].

[fn:1] One is generated via =cargo new=.
